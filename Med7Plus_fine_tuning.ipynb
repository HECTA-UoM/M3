{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# for references\n",
        "#https://spacy.io/usage/processing-pipelines#sourced-components\n",
        "#https://spacy.io/api/doc\n",
        "#https://spacy.io/usage/training\n",
        "#https://spacy.io/usage/saving-loading\n",
        "# https://stackoverflow.com/questions/69181078/spacy-how-do-you-add-custom-ner-labels-to-a-pre-trained-model\n"
      ],
      "metadata": {
        "id": "thomwkubzIeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "jLaUu6jCwTra",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "230c6b1c-c802-42ba-b0a7-adf6bbec7255"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installing Med7 (GLOVE and roberta embeddings) and it's related libraries\n",
        "!python -m pip install jedi\n",
        "!python -m pip install -U wheel pip setuptools pip install spacy==3.4.4 pip install spacy-transformers==1.1.9\n",
        "!python -m pip install https://huggingface.co/kormilitzin/en_core_med7_lg/resolve/main/en_core_med7_lg-any-py3-none-any.whl\n",
        "!python -m pip install https://huggingface.co/kormilitzin/en_core_med7_trf/resolve/main/en_core_med7_trf-any-py3-none-any.whl"
      ],
      "metadata": {
        "id": "Pjr63EN-NM9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7f90f5f1-dcb8-4bb3-9a9e-83ddf395b602"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jedi in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi) (0.8.3)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.41.1)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-68.1.2-py3-none-any.whl (805 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.1/805.1 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting install\n",
            "  Downloading install-1.3.5-py3-none-any.whl (3.2 kB)\n",
            "Collecting spacy==3.4.4\n",
            "  Downloading spacy-3.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy-transformers==1.1.9\n",
            "  Downloading spacy_transformers-1.1.9-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.10/dist-packages (from spacy==3.4.4) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.4.4) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.4.4) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.4.4) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.4.4) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.4.4) (8.1.12)\n",
            "Collecting wasabi<1.1.0,>=0.9.1 (from spacy==3.4.4)\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy==3.4.4) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy==3.4.4) (2.0.9)\n",
            "Collecting typer<0.8.0,>=0.3.0 (from spacy==3.4.4)\n",
            "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy==3.4.4) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.4.4) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.4.4) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.4.4) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.4.4) (2.31.0)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 (from spacy==3.4.4)\n",
            "  Downloading pydantic-1.10.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.4.4) (3.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.4.4) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.4.4) (3.3.0)\n",
            "Collecting transformers<4.26.0,>=3.4.0 (from spacy-transformers==1.1.9)\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers==1.1.9) (2.0.1+cu118)\n",
            "Collecting spacy-alignments<1.0.0,>=0.7.2 (from spacy-transformers==1.1.9)\n",
            "  Downloading spacy_alignments-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy==3.4.4) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.4.4) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.4.4) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.4.4) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.4.4) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy==3.4.4) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy==3.4.4) (0.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->spacy-transformers==1.1.9) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->spacy-transformers==1.1.9) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->spacy-transformers==1.1.9) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->spacy-transformers==1.1.9) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->spacy-transformers==1.1.9) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->spacy-transformers==1.1.9) (16.0.6)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0 (from transformers<4.26.0,>=3.4.0->spacy-transformers==1.1.9)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.26.0,>=3.4.0->spacy-transformers==1.1.9) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.26.0,>=3.4.0->spacy-transformers==1.1.9) (2023.6.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<4.26.0,>=3.4.0->spacy-transformers==1.1.9)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy==3.4.4) (8.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy==3.4.4) (2.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers<4.26.0,>=3.4.0->spacy-transformers==1.1.9) (2023.6.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->spacy-transformers==1.1.9) (1.3.0)\n",
            "Installing collected packages: wasabi, tokenizers, typer, spacy-alignments, setuptools, pydantic, pip, install, huggingface-hub, transformers, spacy, spacy-transformers\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 1.1.2\n",
            "    Uninstalling wasabi-1.1.2:\n",
            "      Successfully uninstalled wasabi-1.1.2\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.0\n",
            "    Uninstalling typer-0.9.0:\n",
            "      Successfully uninstalled typer-0.9.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.1.1\n",
            "    Uninstalling pydantic-2.1.1:\n",
            "      Successfully uninstalled pydantic-2.1.1\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.6.1\n",
            "    Uninstalling spacy-3.6.1:\n",
            "      Successfully uninstalled spacy-3.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.6.0 requires spacy<3.7.0,>=3.6.0, but you have spacy 3.4.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.16.4 install-1.3.5 pip-23.2.1 pydantic-1.10.12 setuptools-68.1.2 spacy-3.4.4 spacy-alignments-0.9.0 spacy-transformers-1.1.9 tokenizers-0.13.3 transformers-4.25.1 typer-0.7.0 wasabi-0.10.1\n",
            "Collecting en-core-med7-lg==any\n",
            "  Downloading https://huggingface.co/kormilitzin/en_core_med7_lg/resolve/main/en_core_med7_lg-any-py3-none-any.whl (607.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m607.4/607.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.2 in /usr/local/lib/python3.10/dist-packages (from en-core-med7-lg==any) (3.4.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (2.0.9)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (68.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (0.1.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (8.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.5.0,>=3.4.2->en-core-med7-lg==any) (2.1.3)\n",
            "Installing collected packages: en-core-med7-lg\n",
            "Successfully installed en-core-med7-lg-3.4.2.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting en-core-med7-trf==any\n",
            "  Downloading https://huggingface.co/kormilitzin/en_core_med7_trf/resolve/main/en_core_med7_trf-any-py3-none-any.whl (1018.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 GB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.2 in /usr/local/lib/python3.10/dist-packages (from en-core-med7-trf==any) (3.4.4)\n",
            "Requirement already satisfied: spacy-transformers<1.2.0,>=1.1.6 in /usr/local/lib/python3.10/dist-packages (from en-core-med7-trf==any) (1.1.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (2.0.9)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (68.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (3.3.0)\n",
            "Requirement already satisfied: transformers<4.26.0,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers<1.2.0,>=1.1.6->en-core-med7-trf==any) (4.25.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers<1.2.0,>=1.1.6->en-core-med7-trf==any) (2.0.1+cu118)\n",
            "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers<1.2.0,>=1.1.6->en-core-med7-trf==any) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (0.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->spacy-transformers<1.2.0,>=1.1.6->en-core-med7-trf==any) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->spacy-transformers<1.2.0,>=1.1.6->en-core-med7-trf==any) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->spacy-transformers<1.2.0,>=1.1.6->en-core-med7-trf==any) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->spacy-transformers<1.2.0,>=1.1.6->en-core-med7-trf==any) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->spacy-transformers<1.2.0,>=1.1.6->en-core-med7-trf==any) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->spacy-transformers<1.2.0,>=1.1.6->en-core-med7-trf==any) (16.0.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from transformers<4.26.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.6->en-core-med7-trf==any) (0.16.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.26.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.6->en-core-med7-trf==any) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.26.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.6->en-core-med7-trf==any) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.26.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.6->en-core-med7-trf==any) (0.13.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (8.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.5.0,>=3.4.2->en-core-med7-trf==any) (2.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers<4.26.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.6->en-core-med7-trf==any) (2023.6.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->spacy-transformers<1.2.0,>=1.1.6->en-core-med7-trf==any) (1.3.0)\n",
            "Installing collected packages: en-core-med7-trf\n",
            "Successfully installed en-core-med7-trf-3.4.2.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT FORGET TO CHANGE THE PATHS AND THE FILES NAMES\n",
        "\n",
        "# this code is to read bert data format (tokens, ner_tags, input_ids, attention_mask, labels)\n",
        "# and change the data format to character offset for spacy ner model\n",
        "# it generate  an excel file with all the tokens in the discharge summary that are labelled as entities only.\n",
        "# you can edit the code to generate an excel file with all the tokens in the discharge summary, either an entity or not\n",
        "# by uncommenting line No 34 \"gold_data.append(gold_data_dic)\"\n",
        "\n",
        "import pandas as pd\n",
        "def preprocess(df, name, path):\n",
        "  gold_data_entities = []\n",
        "  gold_data_tokens = []\n",
        "  for i, tags in enumerate(df.ner_tags.to_list()):\n",
        "    gold = []\n",
        "    ch_start = 0\n",
        "    for l, label in enumerate(tags):\n",
        "      if label == \"O\":\n",
        "        token = df._get_value(i, 'tokens')\n",
        "        tmp_token = token[l]\n",
        "        tmp_label = label\n",
        "        tmp_start = l\n",
        "        tmp_end = l+1\n",
        "\n",
        "        gold_data_dic = {}\n",
        "        ch_end = ch_start + len(tmp_token)\n",
        "        gold_data_dic[\"file_id\"] = i\n",
        "        gold_data_dic['gold_label'] = tmp_label\n",
        "        gold_data_dic['token_start'] = tmp_start\n",
        "        gold_data_dic['token_end'] = tmp_end\n",
        "        gold_data_dic['entity_text'] = tmp_token\n",
        "        gold_data_dic['ch_start'] = ch_start\n",
        "        gold_data_dic['ch_end'] = ch_end\n",
        "        ch_start = ch_end+1\n",
        "        #print(tmp_start, tmp_end, tmp_label, tmp_token)\n",
        "        # uncomment the line below if you want to generate a file with all the tokens (entity or not)\n",
        "        #gold_data_entities.append(gold_data_dic)\n",
        "        gold_data_tokens.append(gold_data_dic)\n",
        "\n",
        "      if label != \"O\":\n",
        "        if \"B-\" in label:\n",
        "          token = df._get_value(i, 'tokens')\n",
        "          tmp_token = token[l]\n",
        "          tmp_label = label[2:]\n",
        "          tmp_start = l\n",
        "\n",
        "          out = 0\n",
        "          if l+1 < len(tags):\n",
        "            tmp_end = l+1\n",
        "            #print(l, l+1, tmp_label, tmp_token)\n",
        "            for nl in range(l+1,len(tags)):\n",
        "              #print(nl, token[nl])\n",
        "              if \"B-\" in tags[nl]:\n",
        "                out = 1\n",
        "                break\n",
        "              elif \"O\" == tags[nl]:\n",
        "                out = 1\n",
        "                break\n",
        "              elif \"I-\" in tags[nl]:\n",
        "                token = df._get_value(i, 'tokens')\n",
        "                tmp_token += \" \" + token[nl]\n",
        "                tmp_start = l\n",
        "                tmp_end = nl+1\n",
        "                #print(tmp_start, tmp_end, tmp_label, tmp_token)\n",
        "            if out == 1:\n",
        "              gold_data_dic = {}\n",
        "\n",
        "              ch_end = ch_start + len(tmp_token)\n",
        "              gold_data_dic[\"file_id\"] = i\n",
        "              gold_data_dic['gold_label'] = tmp_label\n",
        "              gold_data_dic['token_start'] = tmp_start\n",
        "              gold_data_dic['token_end'] = tmp_end\n",
        "              gold_data_dic['entity_text'] = tmp_token\n",
        "              gold_data_dic['ch_start'] = ch_start\n",
        "              gold_data_dic['ch_end'] = ch_end\n",
        "              ch_start = ch_end+1\n",
        "              #print(tmp_start, tmp_end, tmp_label, tmp_token)\n",
        "              gold_data_entities.append(gold_data_dic)\n",
        "              gold_data_tokens.append(gold_data_dic)\n",
        "\n",
        "\n",
        "  gold_data_entity = pd.DataFrame.from_records(gold_data_entities)\n",
        "  gold_data_token = pd.DataFrame.from_records(gold_data_tokens)\n",
        "  print(len(gold_data_entity), len(gold_data_token))\n",
        "  print(gold_data_entity)\n",
        "  print(gold_data_token)\n",
        "\n",
        "  # this line to save the excel file of entities only\n",
        "  gold_data_entity.to_excel(path+'gold_data_entity_CHoffsetEntitiesOnly_'+name+'.xlsx', index=False)\n",
        "\n",
        "  # this line to save the excel file with all tokens\n",
        "  gold_data_token.to_excel(path+'gold_data_entity_CHoffset_all_token_'+name+'.xlsx', index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/collabrations_/HumanLoopH/Med7/data/\"\n",
        "\n",
        "train_validation = pd.read_json(path+\"train_validation_429.json\", lines=True)\n",
        "print(\"pre-processing train_validation set\")\n",
        "preprocess(train_validation, 'train_validation_429', path)\n",
        "\n",
        "train = pd.read_json(path+\"train_353.json\", lines=True)\n",
        "print(\"pre-processing training set\")\n",
        "preprocess(train, 'train_353', path)\n",
        "\n",
        "validation = pd.read_json(path+\"validation_76.json\", lines=True)\n",
        "print(\"pre-processing validation set\")\n",
        "preprocess(validation, 'validation_76', path)\n",
        "\n",
        "test = pd.read_json(path+\"test_76.json\", lines=True)\n",
        "print(\"pre-processing testing set\")\n",
        "preprocess(test, 'test_76', path)\n",
        "\n"
      ],
      "metadata": {
        "id": "R0IkCvJKnF6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f072502f-97cc-4ee6-f10b-f2ee92183e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pre-processing train_validation set\n",
            "70809 850795\n",
            "       file_id gold_label  token_start  token_end         entity_text  \\\n",
            "0            0       Drug           21         22              Keflex   \n",
            "1            0       Drug           22         23             Orencia   \n",
            "2            0       Drug           23         24            Remicade   \n",
            "3            0       Drug          113        114                vanc   \n",
            "4            0       Drug          115        116               cipro   \n",
            "...        ...        ...          ...        ...                 ...   \n",
            "70804      428       Drug         1731       1734  narcotic pain meds   \n",
            "70805      428        ADE         1736       1737        constipating   \n",
            "70806      428     Reason         1764       1765         constipated   \n",
            "70807      428       Drug         1777       1778           Metamucil   \n",
            "70808      428       Drug         1779       1782    Milk of Magnesia   \n",
            "\n",
            "       ch_start  ch_end  \n",
            "0           105     111  \n",
            "1           112     119  \n",
            "2           120     128  \n",
            "3           633     637  \n",
            "4           642     647  \n",
            "...         ...     ...  \n",
            "70804      9474    9492  \n",
            "70805      9500    9512  \n",
            "70806      9657    9668  \n",
            "70807      9726    9735  \n",
            "70808      9739    9755  \n",
            "\n",
            "[70809 rows x 7 columns]\n",
            "        file_id gold_label  token_start  token_end entity_text  ch_start  \\\n",
            "0             0          O            0          1   Admission         0   \n",
            "1             0          O            1          2        Date        10   \n",
            "2             0          O            2          3        2202        15   \n",
            "3             0          O            3          4           1        20   \n",
            "4             0          O            4          5           8        22   \n",
            "...         ...        ...          ...        ...         ...       ...   \n",
            "850790      428          O         2225       2226   Completed     12350   \n",
            "850791      428          O         2226       2227          by     12360   \n",
            "850792      428          O         2227       2228        2142     12363   \n",
            "850793      428          O         2228       2229           8     12368   \n",
            "850794      428          O         2229       2230          28     12370   \n",
            "\n",
            "        ch_end  \n",
            "0            9  \n",
            "1           14  \n",
            "2           19  \n",
            "3           21  \n",
            "4           23  \n",
            "...        ...  \n",
            "850790   12359  \n",
            "850791   12362  \n",
            "850792   12367  \n",
            "850793   12369  \n",
            "850794   12372  \n",
            "\n",
            "[850795 rows x 7 columns]\n",
            "pre-processing training set\n",
            "59212 700032\n",
            "       file_id gold_label  token_start  token_end  \\\n",
            "0            0       Drug           21         22   \n",
            "1            0       Drug           22         23   \n",
            "2            0       Drug           23         24   \n",
            "3            0       Drug          113        114   \n",
            "4            0       Drug          115        116   \n",
            "...        ...        ...          ...        ...   \n",
            "59207      352     Reason         1850       1851   \n",
            "59208      352        ADE         1851       1859   \n",
            "59209      352       Drug         1912       1913   \n",
            "59210      352        ADE         1926       1932   \n",
            "59211      352       Drug         1938       1939   \n",
            "\n",
            "                                             entity_text  ch_start  ch_end  \n",
            "0                                                 Keflex       105     111  \n",
            "1                                                Orencia       112     119  \n",
            "2                                               Remicade       120     128  \n",
            "3                                                   vanc       633     637  \n",
            "4                                                  cipro       642     647  \n",
            "...                                                  ...       ...     ...  \n",
            "59207                                   thrombocytopenia     10616   10632  \n",
            "59208  Acute blood loss anemia from Psoas muscle hema...     10633   10683  \n",
            "59209                                        antibiotics     11101   11112  \n",
            "59210                          a bleed into a hip muscle     11195   11220  \n",
            "59211                                            heparin     11255   11262  \n",
            "\n",
            "[59212 rows x 7 columns]\n",
            "        file_id gold_label  token_start  token_end entity_text  ch_start  \\\n",
            "0             0          O            0          1   Admission         0   \n",
            "1             0          O            1          2        Date        10   \n",
            "2             0          O            2          3        2202        15   \n",
            "3             0          O            3          4           1        20   \n",
            "4             0          O            4          5           8        22   \n",
            "...         ...        ...          ...        ...         ...       ...   \n",
            "700027      352          O         2026       2027  physicians     11811   \n",
            "700028      352          O         2027       2028          at     11822   \n",
            "700029      352          O         2028       2029         the     11825   \n",
            "700030      352          O         2029       2030       rehab     11829   \n",
            "700031      352          O         2030       2031    facility     11835   \n",
            "\n",
            "        ch_end  \n",
            "0            9  \n",
            "1           14  \n",
            "2           19  \n",
            "3           21  \n",
            "4           23  \n",
            "...        ...  \n",
            "700027   11821  \n",
            "700028   11824  \n",
            "700029   11828  \n",
            "700030   11834  \n",
            "700031   11843  \n",
            "\n",
            "[700032 rows x 7 columns]\n",
            "pre-processing validation set\n",
            "11597 150763\n",
            "       file_id gold_label  token_start  token_end         entity_text  \\\n",
            "0            0       Drug           21         22         Penicillins   \n",
            "1            0       Drug           22         23        Levofloxacin   \n",
            "2            0       Drug           23         24         ceftriaxone   \n",
            "3            0       Drug           24         25              Keflex   \n",
            "4            0       Drug           25         26              Flagyl   \n",
            "...        ...        ...          ...        ...                 ...   \n",
            "11592       75       Drug         1731       1734  narcotic pain meds   \n",
            "11593       75        ADE         1736       1737        constipating   \n",
            "11594       75     Reason         1764       1765         constipated   \n",
            "11595       75       Drug         1777       1778           Metamucil   \n",
            "11596       75       Drug         1779       1782    Milk of Magnesia   \n",
            "\n",
            "       ch_start  ch_end  \n",
            "0           106     117  \n",
            "1           118     130  \n",
            "2           131     142  \n",
            "3           143     149  \n",
            "4           150     156  \n",
            "...         ...     ...  \n",
            "11592      9474    9492  \n",
            "11593      9500    9512  \n",
            "11594      9657    9668  \n",
            "11595      9726    9735  \n",
            "11596      9739    9755  \n",
            "\n",
            "[11597 rows x 7 columns]\n",
            "        file_id gold_label  token_start  token_end entity_text  ch_start  \\\n",
            "0             0          O            0          1   Admission         0   \n",
            "1             0          O            1          2        Date        10   \n",
            "2             0          O            2          3        2154        15   \n",
            "3             0          O            3          4           5        20   \n",
            "4             0          O            4          5          30        22   \n",
            "...         ...        ...          ...        ...         ...       ...   \n",
            "150758       75          O         2225       2226   Completed     12350   \n",
            "150759       75          O         2226       2227          by     12360   \n",
            "150760       75          O         2227       2228        2142     12363   \n",
            "150761       75          O         2228       2229           8     12368   \n",
            "150762       75          O         2229       2230          28     12370   \n",
            "\n",
            "        ch_end  \n",
            "0            9  \n",
            "1           14  \n",
            "2           19  \n",
            "3           21  \n",
            "4           24  \n",
            "...        ...  \n",
            "150758   12359  \n",
            "150759   12362  \n",
            "150760   12367  \n",
            "150761   12369  \n",
            "150762   12372  \n",
            "\n",
            "[150763 rows x 7 columns]\n",
            "pre-processing testing set\n",
            "12541 134929\n",
            "       file_id gold_label  token_start  token_end  \\\n",
            "0            0       Drug           21         22   \n",
            "1            0       Drug           22         25   \n",
            "2            0       Drug           25         26   \n",
            "3            0       Drug          115        116   \n",
            "4            0       Drug          124        125   \n",
            "...        ...        ...          ...        ...   \n",
            "12536       75  Frequency          909        911   \n",
            "12537       75       Drug          986        987   \n",
            "12538       75       Drug          988        989   \n",
            "12539       75       Drug          990        991   \n",
            "12540       75       Drug          992        993   \n",
            "\n",
            "                         entity_text  ch_start  ch_end  \n",
            "0                        Penicillins       108     119  \n",
            "1      Sulfa Sulfonamide Antibiotics       120     149  \n",
            "2                           Lamictal       150     158  \n",
            "3                        Clindamycin       734     745  \n",
            "4                           Levaquin       778     786  \n",
            "...                              ...       ...     ...  \n",
            "12536                          q day      5535    5540  \n",
            "12537                       Percocet      6038    6046  \n",
            "12538                         Motrin      6049    6055  \n",
            "12539                         Celexa      6058    6064  \n",
            "12540                          Lasix      6067    6072  \n",
            "\n",
            "[12541 rows x 7 columns]\n",
            "        file_id gold_label  token_start  token_end entity_text  ch_start  \\\n",
            "0             0          O            0          1   Admission         0   \n",
            "1             0          O            1          2        Date        10   \n",
            "2             0          O            2          3        2178        15   \n",
            "3             0          O            3          4          10        20   \n",
            "4             0          O            4          5          14        23   \n",
            "...         ...        ...          ...        ...         ...       ...   \n",
            "134924       75          O         1020       1021          23      6200   \n",
            "134925       75          O         1021       1022         JOB      6203   \n",
            "134926       75          O         1022       1023         Job      6207   \n",
            "134927       75          O         1023       1024      Number      6211   \n",
            "134928       75          O         1024       1025       49231      6218   \n",
            "\n",
            "        ch_end  \n",
            "0            9  \n",
            "1           14  \n",
            "2           19  \n",
            "3           22  \n",
            "4           25  \n",
            "...        ...  \n",
            "134924    6202  \n",
            "134925    6206  \n",
            "134926    6210  \n",
            "134927    6217  \n",
            "134928    6223  \n",
            "\n",
            "[134929 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the results of en_core_med7_trf and en_core_med7_lg on testing set WITHOUT fine-tuining\n",
        "\n",
        "# 1- create one discharge summary with its NER labels\n",
        "# 2- send the summary to Med7 for prediction NER labels\n",
        "# 3- evaluate the results with Gold standard\n",
        "\n",
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "\n",
        "def testing(df, name, path):\n",
        "\n",
        "  med7 = spacy.load(name)\n",
        "\n",
        "  str_dic_lg = []\n",
        "  predict_labels_lg_dic = []\n",
        "  predict_labels_lg = []\n",
        "  for i, token in enumerate(df.tokens.to_list()):\n",
        "    token_str_lg = ' '.join(str(t) for t in token)\n",
        "    labels_lg = df._get_value(i, 'ner_tags')\n",
        "    str_dic_lg.append([token_str_lg, labels_lg])\n",
        "    predicts_lg = []\n",
        "    entities = med7(token_str_lg)\n",
        "    for e in entities.ents:\n",
        "      predict_dic = {}\n",
        "      predict_dic[\"predict_file_id\"] = i\n",
        "      predict_dic['predict_label'] = e.label_\n",
        "      predict_dic['predict_start'] = e.start\n",
        "      predict_dic['predict_end'] = e.end\n",
        "      predict_dic['predict_text'] = e.text\n",
        "      predict_dic['start_char'] = e.start_char\n",
        "      predict_dic['end_char'] = e.end_char\n",
        "\n",
        "      #print(\"e.text\", e.text)\n",
        "      #print(\"e.label_\", e.label_)\n",
        "      #print('start', e.start)\n",
        "      #print('end', e.end)\n",
        "      #print('char_span', e.char_span(e.start_char, e.end_char))\n",
        "      #print('start_char', e.start_char)\n",
        "      #print('end_char', e.end_char)\n",
        "      #print('ent_id', e.ent_id)\n",
        "      #print('ent_id_', e.ent_id_)\n",
        "      #print('ents', e.ents[0])\n",
        "      #print('label', e.label)\n",
        "      #print('id', e.id)\n",
        "      #print('id_', e.id_)\n",
        "\n",
        "      predict_labels_lg_dic.append(predict_dic)\n",
        "      predicts_lg.append([e.start, e.end, e.text, e.label_])\n",
        "    print(predict_dic)\n",
        "    predict_labels_lg.append(predicts_lg)\n",
        "\n",
        "  print(len(predict_labels_lg))\n",
        "  print(len(predict_labels_lg_dic))\n",
        "  predict_label_entity = pd.DataFrame.from_records(predict_labels_lg_dic)\n",
        "  print(predict_label_entity)\n",
        "\n",
        "  # uncomment the line below to save the output of MED7 prediction\n",
        "  predict_label_entity.to_excel(path + 'predict_label_entity_76testDataset_'+name+'.xlsx', index=False)\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/collabrations_/HumanLoopH/Med7/data/\"\n",
        "df = pd.read_json(path+\"test_76.json\", lines=True)\n",
        "model = [\"en_core_med7_lg\", \"en_core_med7_trf\"]\n",
        "for name in model:\n",
        "  print(\"testing the performance of \"+name+\" over the testing set\")\n",
        "  testing(df, name, path)\n"
      ],
      "metadata": {
        "id": "8BHr41C1NaJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "377da905-cb4b-4073-b145-658631e95ab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing the performance of en_core_med7_lg over the testing set\n",
            "{'predict_file_id': 0, 'predict_label': 'DRUG', 'predict_start': 2594, 'predict_end': 2595, 'predict_text': 'lamictal', 'start_char': 14739, 'end_char': 14747}\n",
            "{'predict_file_id': 1, 'predict_label': 'FREQUENCY', 'predict_start': 3244, 'predict_end': 3245, 'predict_text': 'PRN', 'start_char': 18543, 'end_char': 18546}\n",
            "{'predict_file_id': 2, 'predict_label': 'DRUG', 'predict_start': 3204, 'predict_end': 3205, 'predict_text': 'lovenox', 'start_char': 17675, 'end_char': 17682}\n",
            "{'predict_file_id': 3, 'predict_label': 'FREQUENCY', 'predict_start': 808, 'predict_end': 810, 'predict_text': 'q MWF', 'start_char': 4444, 'end_char': 4449}\n",
            "{'predict_file_id': 4, 'predict_label': 'DURATION', 'predict_start': 1577, 'predict_end': 1581, 'predict_text': 'for 5 more days', 'start_char': 8978, 'end_char': 8993}\n",
            "{'predict_file_id': 5, 'predict_label': 'DRUG', 'predict_start': 2481, 'predict_end': 2482, 'predict_text': 'Ciprofloxacin', 'start_char': 13417, 'end_char': 13430}\n",
            "{'predict_file_id': 6, 'predict_label': 'FREQUENCY', 'predict_start': 1141, 'predict_end': 1143, 'predict_text': 'per day', 'start_char': 5896, 'end_char': 5903}\n",
            "{'predict_file_id': 7, 'predict_label': 'FREQUENCY', 'predict_start': 111, 'predict_end': 113, 'predict_text': 'q day', 'start_char': 541, 'end_char': 546}\n",
            "{'predict_file_id': 8, 'predict_label': 'DOSAGE', 'predict_start': 1570, 'predict_end': 1571, 'predict_text': '4', 'start_char': 9103, 'end_char': 9104}\n",
            "{'predict_file_id': 9, 'predict_label': 'FREQUENCY', 'predict_start': 587, 'predict_end': 588, 'predict_text': 'ASDIR', 'start_char': 3223, 'end_char': 3228}\n",
            "{'predict_file_id': 10, 'predict_label': 'DRUG', 'predict_start': 1628, 'predict_end': 1629, 'predict_text': 'THIAZIDE', 'start_char': 8501, 'end_char': 8509}\n",
            "{'predict_file_id': 11, 'predict_label': 'FREQUENCY', 'predict_start': 1743, 'predict_end': 1745, 'predict_text': 'every morning', 'start_char': 9782, 'end_char': 9795}\n",
            "{'predict_file_id': 12, 'predict_label': 'FREQUENCY', 'predict_start': 1715, 'predict_end': 1719, 'predict_text': 'four times a day', 'start_char': 9694, 'end_char': 9710}\n",
            "{'predict_file_id': 13, 'predict_label': 'DOSAGE', 'predict_start': 1954, 'predict_end': 1955, 'predict_text': '1', 'start_char': 11112, 'end_char': 11113}\n",
            "{'predict_file_id': 14, 'predict_label': 'ROUTE', 'predict_start': 2912, 'predict_end': 2914, 'predict_text': 'nasal cannula', 'start_char': 16870, 'end_char': 16883}\n",
            "{'predict_file_id': 15, 'predict_label': 'DOSAGE', 'predict_start': 686, 'predict_end': 687, 'predict_text': '60', 'start_char': 3470, 'end_char': 3472}\n",
            "{'predict_file_id': 16, 'predict_label': 'DRUG', 'predict_start': 76, 'predict_end': 77, 'predict_text': 'Megace', 'start_char': 459, 'end_char': 465}\n",
            "{'predict_file_id': 17, 'predict_label': 'FREQUENCY', 'predict_start': 418, 'predict_end': 421, 'predict_text': 'q eight hours', 'start_char': 2528, 'end_char': 2541}\n",
            "{'predict_file_id': 18, 'predict_label': 'DRUG', 'predict_start': 2018, 'predict_end': 2021, 'predict_text': 'narcotic pain medication', 'start_char': 11245, 'end_char': 11269}\n",
            "{'predict_file_id': 19, 'predict_label': 'FORM', 'predict_start': 2479, 'predict_end': 2480, 'predict_text': 'gum', 'start_char': 13976, 'end_char': 13979}\n",
            "{'predict_file_id': 20, 'predict_label': 'FORM', 'predict_start': 1716, 'predict_end': 1717, 'predict_text': 'patch', 'start_char': 9744, 'end_char': 9749}\n",
            "{'predict_file_id': 21, 'predict_label': 'FREQUENCY', 'predict_start': 2153, 'predict_end': 2155, 'predict_text': 'as needed', 'start_char': 12633, 'end_char': 12642}\n",
            "{'predict_file_id': 22, 'predict_label': 'DRUG', 'predict_start': 602, 'predict_end': 603, 'predict_text': 'vasopressors', 'start_char': 3557, 'end_char': 3569}\n",
            "{'predict_file_id': 23, 'predict_label': 'DOSAGE', 'predict_start': 2151, 'predict_end': 2152, 'predict_text': 'taper', 'start_char': 12526, 'end_char': 12531}\n",
            "{'predict_file_id': 24, 'predict_label': 'FREQUENCY', 'predict_start': 1474, 'predict_end': 1476, 'predict_text': 'with meals', 'start_char': 8167, 'end_char': 8177}\n",
            "{'predict_file_id': 25, 'predict_label': 'DOSAGE', 'predict_start': 2987, 'predict_end': 2988, 'predict_text': '3', 'start_char': 17396, 'end_char': 17397}\n",
            "{'predict_file_id': 26, 'predict_label': 'FREQUENCY', 'predict_start': 2195, 'predict_end': 2197, 'predict_text': 'as needed', 'start_char': 11840, 'end_char': 11849}\n",
            "{'predict_file_id': 27, 'predict_label': 'DRUG', 'predict_start': 1232, 'predict_end': 1233, 'predict_text': 'ciprofloxacin', 'start_char': 6996, 'end_char': 7009}\n",
            "{'predict_file_id': 28, 'predict_label': 'FREQUENCY', 'predict_start': 759, 'predict_end': 762, 'predict_text': 'once a day', 'start_char': 4324, 'end_char': 4334}\n",
            "{'predict_file_id': 29, 'predict_label': 'DRUG', 'predict_start': 1890, 'predict_end': 1891, 'predict_text': 'steroid', 'start_char': 10095, 'end_char': 10102}\n",
            "{'predict_file_id': 30, 'predict_label': 'DRUG', 'predict_start': 1672, 'predict_end': 1674, 'predict_text': 'stool softeners', 'start_char': 9074, 'end_char': 9089}\n",
            "{'predict_file_id': 31, 'predict_label': 'FREQUENCY', 'predict_start': 1987, 'predict_end': 1990, 'predict_text': 'once per day', 'start_char': 11677, 'end_char': 11689}\n",
            "{'predict_file_id': 32, 'predict_label': 'FREQUENCY', 'predict_start': 1642, 'predict_end': 1643, 'predict_text': 'daily', 'start_char': 8481, 'end_char': 8486}\n",
            "{'predict_file_id': 33, 'predict_label': 'DRUG', 'predict_start': 3608, 'predict_end': 3609, 'predict_text': 'antibiotics', 'start_char': 20527, 'end_char': 20538}\n",
            "{'predict_file_id': 34, 'predict_label': 'DRUG', 'predict_start': 1339, 'predict_end': 1340, 'predict_text': 'Keppra', 'start_char': 7565, 'end_char': 7571}\n",
            "{'predict_file_id': 35, 'predict_label': 'DOSAGE', 'predict_start': 1153, 'predict_end': 1154, 'predict_text': '1', 'start_char': 6586, 'end_char': 6587}\n",
            "{'predict_file_id': 36, 'predict_label': 'FREQUENCY', 'predict_start': 1160, 'predict_end': 1163, 'predict_text': 'q 8 h', 'start_char': 7107, 'end_char': 7112}\n",
            "{'predict_file_id': 37, 'predict_label': 'DURATION', 'predict_start': 2120, 'predict_end': 2122, 'predict_text': '2 weeks', 'start_char': 11478, 'end_char': 11485}\n",
            "{'predict_file_id': 38, 'predict_label': 'DOSAGE', 'predict_start': 1648, 'predict_end': 1649, 'predict_text': '28', 'start_char': 9635, 'end_char': 9637}\n",
            "{'predict_file_id': 39, 'predict_label': 'DRUG', 'predict_start': 2059, 'predict_end': 2060, 'predict_text': 'Methylphenidate', 'start_char': 11933, 'end_char': 11948}\n",
            "{'predict_file_id': 40, 'predict_label': 'FREQUENCY', 'predict_start': 2747, 'predict_end': 2749, 'predict_text': 'every day', 'start_char': 15442, 'end_char': 15451}\n",
            "{'predict_file_id': 41, 'predict_label': 'DRUG', 'predict_start': 919, 'predict_end': 920, 'predict_text': 'bicarbonate', 'start_char': 5205, 'end_char': 5216}\n",
            "{'predict_file_id': 42, 'predict_label': 'FREQUENCY', 'predict_start': 1350, 'predict_end': 1355, 'predict_text': 'once a day as needed', 'start_char': 7845, 'end_char': 7865}\n",
            "{'predict_file_id': 43, 'predict_label': 'FREQUENCY', 'predict_start': 1458, 'predict_end': 1464, 'predict_text': 'every eight 8 hours as needed', 'start_char': 7717, 'end_char': 7746}\n",
            "{'predict_file_id': 44, 'predict_label': 'FREQUENCY', 'predict_start': 2541, 'predict_end': 2542, 'predict_text': 'daily', 'start_char': 14527, 'end_char': 14532}\n",
            "{'predict_file_id': 45, 'predict_label': 'DRUG', 'predict_start': 675, 'predict_end': 676, 'predict_text': 'lipitor', 'start_char': 3648, 'end_char': 3655}\n",
            "{'predict_file_id': 46, 'predict_label': 'DRUG', 'predict_start': 1933, 'predict_end': 1934, 'predict_text': 'steroids', 'start_char': 10323, 'end_char': 10331}\n",
            "{'predict_file_id': 47, 'predict_label': 'FREQUENCY', 'predict_start': 3234, 'predict_end': 3235, 'predict_text': 'daily', 'start_char': 18059, 'end_char': 18064}\n",
            "{'predict_file_id': 48, 'predict_label': 'DRUG', 'predict_start': 2436, 'predict_end': 2440, 'predict_text': 'hypoglycemic medication Followup Instructions', 'start_char': 13620, 'end_char': 13665}\n",
            "{'predict_file_id': 49, 'predict_label': 'DURATION', 'predict_start': 2084, 'predict_end': 2087, 'predict_text': 'for 2 days', 'start_char': 11713, 'end_char': 11723}\n",
            "{'predict_file_id': 50, 'predict_label': 'DURATION', 'predict_start': 115, 'predict_end': 117, 'predict_text': '14 days', 'start_char': 715, 'end_char': 722}\n",
            "{'predict_file_id': 51, 'predict_label': 'DRUG', 'predict_start': 2380, 'predict_end': 2381, 'predict_text': 'LISINOPRIL', 'start_char': 13707, 'end_char': 13717}\n",
            "{'predict_file_id': 52, 'predict_label': 'FREQUENCY', 'predict_start': 1640, 'predict_end': 1643, 'predict_text': 'every 8 hours', 'start_char': 9139, 'end_char': 9152}\n",
            "{'predict_file_id': 53, 'predict_label': 'FREQUENCY', 'predict_start': 1208, 'predict_end': 1212, 'predict_text': 'bid times six days', 'start_char': 7051, 'end_char': 7069}\n",
            "{'predict_file_id': 54, 'predict_label': 'DURATION', 'predict_start': 1041, 'predict_end': 1044, 'predict_text': 'x 4 days', 'start_char': 6061, 'end_char': 6069}\n",
            "{'predict_file_id': 55, 'predict_label': 'FREQUENCY', 'predict_start': 2376, 'predict_end': 2379, 'predict_text': 'once a day', 'start_char': 13244, 'end_char': 13254}\n",
            "{'predict_file_id': 56, 'predict_label': 'FREQUENCY', 'predict_start': 1511, 'predict_end': 1512, 'predict_text': 'qPM', 'start_char': 8111, 'end_char': 8114}\n",
            "{'predict_file_id': 57, 'predict_label': 'FREQUENCY', 'predict_start': 1807, 'predict_end': 1808, 'predict_text': 'daily', 'start_char': 9915, 'end_char': 9920}\n",
            "{'predict_file_id': 58, 'predict_label': 'FREQUENCY', 'predict_start': 1577, 'predict_end': 1579, 'predict_text': 'TID PRN', 'start_char': 9507, 'end_char': 9514}\n",
            "{'predict_file_id': 59, 'predict_label': 'DOSAGE', 'predict_start': 1404, 'predict_end': 1405, 'predict_text': '1', 'start_char': 7608, 'end_char': 7609}\n",
            "{'predict_file_id': 60, 'predict_label': 'DRUG', 'predict_start': 3060, 'predict_end': 3061, 'predict_text': 'Oxybutynin', 'start_char': 17587, 'end_char': 17597}\n",
            "{'predict_file_id': 61, 'predict_label': 'DRUG', 'predict_start': 1069, 'predict_end': 1070, 'predict_text': 'Ativan', 'start_char': 6226, 'end_char': 6232}\n",
            "{'predict_file_id': 62, 'predict_label': 'DRUG', 'predict_start': 2464, 'predict_end': 2465, 'predict_text': 'metoprolol', 'start_char': 13288, 'end_char': 13298}\n",
            "{'predict_file_id': 63, 'predict_label': 'DURATION', 'predict_start': 2144, 'predict_end': 2147, 'predict_text': 'for 7 days', 'start_char': 11882, 'end_char': 11892}\n",
            "{'predict_file_id': 64, 'predict_label': 'DRUG', 'predict_start': 2097, 'predict_end': 2098, 'predict_text': 'Tylenol', 'start_char': 11694, 'end_char': 11701}\n",
            "{'predict_file_id': 65, 'predict_label': 'DRUG', 'predict_start': 944, 'predict_end': 945, 'predict_text': 'antibotics', 'start_char': 5154, 'end_char': 5164}\n",
            "{'predict_file_id': 66, 'predict_label': 'FORM', 'predict_start': 1922, 'predict_end': 1927, 'predict_text': 'Tablet Rapid Dissolve s Refills', 'start_char': 10444, 'end_char': 10475}\n",
            "{'predict_file_id': 67, 'predict_label': 'DRUG', 'predict_start': 3420, 'predict_end': 3421, 'predict_text': 'enoxaparin', 'start_char': 19186, 'end_char': 19196}\n",
            "{'predict_file_id': 68, 'predict_label': 'DRUG', 'predict_start': 1720, 'predict_end': 1721, 'predict_text': 'AMLODIPINE', 'start_char': 9216, 'end_char': 9226}\n",
            "{'predict_file_id': 69, 'predict_label': 'FREQUENCY', 'predict_start': 2131, 'predict_end': 2133, 'predict_text': 'as needed', 'start_char': 11553, 'end_char': 11562}\n",
            "{'predict_file_id': 70, 'predict_label': 'FREQUENCY', 'predict_start': 2368, 'predict_end': 2374, 'predict_text': 'every eight 8 hours as needed', 'start_char': 13755, 'end_char': 13784}\n",
            "{'predict_file_id': 71, 'predict_label': 'FORM', 'predict_start': 2161, 'predict_end': 2162, 'predict_text': 'patches', 'start_char': 11692, 'end_char': 11699}\n",
            "{'predict_file_id': 72, 'predict_label': 'DRUG', 'predict_start': 4132, 'predict_end': 4133, 'predict_text': 'vancomycin', 'start_char': 21831, 'end_char': 21841}\n",
            "{'predict_file_id': 73, 'predict_label': 'STRENGTH', 'predict_start': 1080, 'predict_end': 1082, 'predict_text': '5mg', 'start_char': 6203, 'end_char': 6206}\n",
            "{'predict_file_id': 74, 'predict_label': 'STRENGTH', 'predict_start': 820, 'predict_end': 821, 'predict_text': '1', 'start_char': 4873, 'end_char': 4874}\n",
            "{'predict_file_id': 75, 'predict_label': 'STRENGTH', 'predict_start': 991, 'predict_end': 993, 'predict_text': '4 Lasix', 'start_char': 6065, 'end_char': 6072}\n",
            "76\n",
            "12055\n",
            "       predict_file_id predict_label  predict_start  predict_end predict_text  \\\n",
            "0                    0          DRUG             21           22  Penicillins   \n",
            "1                    0          DRUG            115          116  Clindamycin   \n",
            "2                    0        DOSAGE            117          118            1   \n",
            "3                    0          DRUG            124          125     Levaquin   \n",
            "4                    0          DRUG            126          127   Vancomycin   \n",
            "...                ...           ...            ...          ...          ...   \n",
            "12050               75          DRUG            986          987     Percocet   \n",
            "12051               75      STRENGTH            987          989     2 Motrin   \n",
            "12052               75        DOSAGE            989          990            3   \n",
            "12053               75          DRUG            990          991       Celexa   \n",
            "12054               75      STRENGTH            991          993      4 Lasix   \n",
            "\n",
            "       start_char  end_char  \n",
            "0             108       119  \n",
            "1             734       745  \n",
            "2             748       749  \n",
            "3             778       786  \n",
            "4             791       801  \n",
            "...           ...       ...  \n",
            "12050        6038      6046  \n",
            "12051        6047      6055  \n",
            "12052        6056      6057  \n",
            "12053        6058      6064  \n",
            "12054        6065      6072  \n",
            "\n",
            "[12055 rows x 7 columns]\n",
            "testing the performance of en_core_med7_trf over the testing set\n",
            "{'predict_file_id': 0, 'predict_label': 'DRUG', 'predict_start': 2594, 'predict_end': 2595, 'predict_text': 'lamictal', 'start_char': 14739, 'end_char': 14747}\n",
            "{'predict_file_id': 1, 'predict_label': 'FREQUENCY', 'predict_start': 3121, 'predict_end': 3127, 'predict_text': 'every six 6 hours as needed', 'start_char': 17706, 'end_char': 17733}\n",
            "{'predict_file_id': 2, 'predict_label': 'DRUG', 'predict_start': 3204, 'predict_end': 3205, 'predict_text': 'lovenox', 'start_char': 17675, 'end_char': 17682}\n",
            "{'predict_file_id': 3, 'predict_label': 'FREQUENCY', 'predict_start': 808, 'predict_end': 810, 'predict_text': 'q MWF', 'start_char': 4444, 'end_char': 4449}\n",
            "{'predict_file_id': 4, 'predict_label': 'DURATION', 'predict_start': 1577, 'predict_end': 1581, 'predict_text': 'for 5 more days', 'start_char': 8978, 'end_char': 8993}\n",
            "{'predict_file_id': 5, 'predict_label': 'DRUG', 'predict_start': 2481, 'predict_end': 2482, 'predict_text': 'Ciprofloxacin', 'start_char': 13417, 'end_char': 13430}\n",
            "{'predict_file_id': 6, 'predict_label': 'DRUG', 'predict_start': 1118, 'predict_end': 1119, 'predict_text': 'Hydrochlorthiazide', 'start_char': 5748, 'end_char': 5766}\n",
            "{'predict_file_id': 7, 'predict_label': 'FREQUENCY', 'predict_start': 111, 'predict_end': 113, 'predict_text': 'q day', 'start_char': 541, 'end_char': 546}\n",
            "{'predict_file_id': 8, 'predict_label': 'FREQUENCY', 'predict_start': 1432, 'predict_end': 1437, 'predict_text': 'once a day as needed', 'start_char': 8211, 'end_char': 8231}\n",
            "{'predict_file_id': 9, 'predict_label': 'FREQUENCY', 'predict_start': 587, 'predict_end': 588, 'predict_text': 'ASDIR', 'start_char': 3223, 'end_char': 3228}\n",
            "{'predict_file_id': 10, 'predict_label': 'DRUG', 'predict_start': 1674, 'predict_end': 1676, 'predict_text': 'pneumococcal vaccine', 'start_char': 8766, 'end_char': 8786}\n",
            "{'predict_file_id': 11, 'predict_label': 'DRUG', 'predict_start': 1740, 'predict_end': 1741, 'predict_text': 'metoprolol', 'start_char': 9756, 'end_char': 9766}\n",
            "{'predict_file_id': 12, 'predict_label': 'FREQUENCY', 'predict_start': 1715, 'predict_end': 1719, 'predict_text': 'four times a day', 'start_char': 9694, 'end_char': 9710}\n",
            "{'predict_file_id': 13, 'predict_label': 'STRENGTH', 'predict_start': 1933, 'predict_end': 1935, 'predict_text': '150 mg', 'start_char': 10983, 'end_char': 10989}\n",
            "{'predict_file_id': 14, 'predict_label': 'ROUTE', 'predict_start': 2912, 'predict_end': 2914, 'predict_text': 'nasal cannula', 'start_char': 16870, 'end_char': 16883}\n",
            "{'predict_file_id': 15, 'predict_label': 'FORM', 'predict_start': 687, 'predict_end': 688, 'predict_text': 'Capsule', 'start_char': 3473, 'end_char': 3480}\n",
            "{'predict_file_id': 16, 'predict_label': 'DRUG', 'predict_start': 76, 'predict_end': 77, 'predict_text': 'Megace', 'start_char': 459, 'end_char': 465}\n",
            "{'predict_file_id': 17, 'predict_label': 'FREQUENCY', 'predict_start': 418, 'predict_end': 421, 'predict_text': 'q eight hours', 'start_char': 2528, 'end_char': 2541}\n",
            "{'predict_file_id': 18, 'predict_label': 'DRUG', 'predict_start': 2018, 'predict_end': 2021, 'predict_text': 'narcotic pain medication', 'start_char': 11245, 'end_char': 11269}\n",
            "{'predict_file_id': 19, 'predict_label': 'FORM', 'predict_start': 2479, 'predict_end': 2480, 'predict_text': 'gum', 'start_char': 13976, 'end_char': 13979}\n",
            "{'predict_file_id': 20, 'predict_label': 'FORM', 'predict_start': 1723, 'predict_end': 1724, 'predict_text': 'patch', 'start_char': 9776, 'end_char': 9781}\n",
            "{'predict_file_id': 21, 'predict_label': 'FREQUENCY', 'predict_start': 2153, 'predict_end': 2155, 'predict_text': 'as needed', 'start_char': 12633, 'end_char': 12642}\n",
            "{'predict_file_id': 22, 'predict_label': 'DRUG', 'predict_start': 602, 'predict_end': 603, 'predict_text': 'vasopressors', 'start_char': 3557, 'end_char': 3569}\n",
            "{'predict_file_id': 23, 'predict_label': 'DOSAGE', 'predict_start': 2151, 'predict_end': 2152, 'predict_text': 'taper', 'start_char': 12526, 'end_char': 12531}\n",
            "{'predict_file_id': 24, 'predict_label': 'DRUG', 'predict_start': 1470, 'predict_end': 1474, 'predict_text': 'Phos Lo calcium acetate', 'start_char': 8143, 'end_char': 8166}\n",
            "{'predict_file_id': 25, 'predict_label': 'DRUG', 'predict_start': 2672, 'predict_end': 2674, 'predict_text': 'pain medications', 'start_char': 15633, 'end_char': 15649}\n",
            "{'predict_file_id': 26, 'predict_label': 'DRUG', 'predict_start': 2193, 'predict_end': 2194, 'predict_text': 'warfarin', 'start_char': 11826, 'end_char': 11834}\n",
            "{'predict_file_id': 27, 'predict_label': 'DRUG', 'predict_start': 1232, 'predict_end': 1233, 'predict_text': 'ciprofloxacin', 'start_char': 6996, 'end_char': 7009}\n",
            "{'predict_file_id': 28, 'predict_label': 'ROUTE', 'predict_start': 757, 'predict_end': 759, 'predict_text': 'by mouth', 'start_char': 4315, 'end_char': 4323}\n",
            "{'predict_file_id': 29, 'predict_label': 'DRUG', 'predict_start': 1905, 'predict_end': 1906, 'predict_text': 'supplements', 'start_char': 10172, 'end_char': 10183}\n",
            "{'predict_file_id': 30, 'predict_label': 'DRUG', 'predict_start': 1672, 'predict_end': 1674, 'predict_text': 'stool softeners', 'start_char': 9074, 'end_char': 9089}\n",
            "{'predict_file_id': 31, 'predict_label': 'ROUTE', 'predict_start': 1985, 'predict_end': 1987, 'predict_text': 'by mouth', 'start_char': 11668, 'end_char': 11676}\n",
            "{'predict_file_id': 32, 'predict_label': 'FREQUENCY', 'predict_start': 1642, 'predict_end': 1643, 'predict_text': 'daily', 'start_char': 8481, 'end_char': 8486}\n",
            "{'predict_file_id': 33, 'predict_label': 'DRUG', 'predict_start': 3608, 'predict_end': 3609, 'predict_text': 'antibiotics', 'start_char': 20527, 'end_char': 20538}\n",
            "{'predict_file_id': 34, 'predict_label': 'DRUG', 'predict_start': 1339, 'predict_end': 1340, 'predict_text': 'Keppra', 'start_char': 7565, 'end_char': 7571}\n",
            "{'predict_file_id': 35, 'predict_label': 'FREQUENCY', 'predict_start': 1095, 'predict_end': 1099, 'predict_text': 'BID prn as needed', 'start_char': 6149, 'end_char': 6166}\n",
            "{'predict_file_id': 36, 'predict_label': 'FREQUENCY', 'predict_start': 1160, 'predict_end': 1163, 'predict_text': 'q 8 h', 'start_char': 7107, 'end_char': 7112}\n",
            "{'predict_file_id': 37, 'predict_label': 'FORM', 'predict_start': 2071, 'predict_end': 2072, 'predict_text': 'Tablet', 'start_char': 11155, 'end_char': 11161}\n",
            "{'predict_file_id': 38, 'predict_label': 'FORM', 'predict_start': 1649, 'predict_end': 1650, 'predict_text': 'Tablet', 'start_char': 9638, 'end_char': 9644}\n",
            "{'predict_file_id': 39, 'predict_label': 'DRUG', 'predict_start': 2059, 'predict_end': 2060, 'predict_text': 'Methylphenidate', 'start_char': 11933, 'end_char': 11948}\n",
            "{'predict_file_id': 40, 'predict_label': 'FREQUENCY', 'predict_start': 2747, 'predict_end': 2749, 'predict_text': 'every day', 'start_char': 15442, 'end_char': 15451}\n",
            "{'predict_file_id': 41, 'predict_label': 'STRENGTH', 'predict_start': 816, 'predict_end': 818, 'predict_text': '29 units', 'start_char': 4680, 'end_char': 4688}\n",
            "{'predict_file_id': 42, 'predict_label': 'FREQUENCY', 'predict_start': 1350, 'predict_end': 1355, 'predict_text': 'once a day as needed', 'start_char': 7845, 'end_char': 7865}\n",
            "{'predict_file_id': 43, 'predict_label': 'FREQUENCY', 'predict_start': 1458, 'predict_end': 1464, 'predict_text': 'every eight 8 hours as needed', 'start_char': 7717, 'end_char': 7746}\n",
            "{'predict_file_id': 44, 'predict_label': 'FREQUENCY', 'predict_start': 2541, 'predict_end': 2542, 'predict_text': 'daily', 'start_char': 14527, 'end_char': 14532}\n",
            "{'predict_file_id': 45, 'predict_label': 'DRUG', 'predict_start': 675, 'predict_end': 676, 'predict_text': 'lipitor', 'start_char': 3648, 'end_char': 3655}\n",
            "{'predict_file_id': 46, 'predict_label': 'DRUG', 'predict_start': 1933, 'predict_end': 1934, 'predict_text': 'steroids', 'start_char': 10323, 'end_char': 10331}\n",
            "{'predict_file_id': 47, 'predict_label': 'FREQUENCY', 'predict_start': 3234, 'predict_end': 3235, 'predict_text': 'daily', 'start_char': 18059, 'end_char': 18064}\n",
            "{'predict_file_id': 48, 'predict_label': 'DRUG', 'predict_start': 2436, 'predict_end': 2438, 'predict_text': 'hypoglycemic medication', 'start_char': 13620, 'end_char': 13643}\n",
            "{'predict_file_id': 49, 'predict_label': 'DURATION', 'predict_start': 2084, 'predict_end': 2087, 'predict_text': 'for 2 days', 'start_char': 11713, 'end_char': 11723}\n",
            "{'predict_file_id': 50, 'predict_label': 'DURATION', 'predict_start': 115, 'predict_end': 117, 'predict_text': '14 days', 'start_char': 715, 'end_char': 722}\n",
            "{'predict_file_id': 51, 'predict_label': 'DRUG', 'predict_start': 2391, 'predict_end': 2394, 'predict_text': 'anti hypertensive medications', 'start_char': 13779, 'end_char': 13808}\n",
            "{'predict_file_id': 52, 'predict_label': 'DOSAGE', 'predict_start': 1639, 'predict_end': 1640, 'predict_text': 'one', 'start_char': 9135, 'end_char': 9138}\n",
            "{'predict_file_id': 53, 'predict_label': 'DURATION', 'predict_start': 1210, 'predict_end': 1212, 'predict_text': 'six days', 'start_char': 7061, 'end_char': 7069}\n",
            "{'predict_file_id': 54, 'predict_label': 'DURATION', 'predict_start': 1042, 'predict_end': 1044, 'predict_text': '4 days', 'start_char': 6063, 'end_char': 6069}\n",
            "{'predict_file_id': 55, 'predict_label': 'FORM', 'predict_start': 2386, 'predict_end': 2387, 'predict_text': 'Tablet', 'start_char': 13293, 'end_char': 13299}\n",
            "{'predict_file_id': 56, 'predict_label': 'FREQUENCY', 'predict_start': 1511, 'predict_end': 1512, 'predict_text': 'qPM', 'start_char': 8111, 'end_char': 8114}\n",
            "{'predict_file_id': 57, 'predict_label': 'DRUG', 'predict_start': 1848, 'predict_end': 1850, 'predict_text': 'pain medication', 'start_char': 10152, 'end_char': 10167}\n",
            "{'predict_file_id': 58, 'predict_label': 'FREQUENCY', 'predict_start': 1577, 'predict_end': 1579, 'predict_text': 'TID PRN', 'start_char': 9507, 'end_char': 9514}\n",
            "{'predict_file_id': 59, 'predict_label': 'STRENGTH', 'predict_start': 1255, 'predict_end': 1257, 'predict_text': '4000 mg', 'start_char': 6738, 'end_char': 6745}\n",
            "{'predict_file_id': 60, 'predict_label': 'DRUG', 'predict_start': 3060, 'predict_end': 3061, 'predict_text': 'Oxybutynin', 'start_char': 17587, 'end_char': 17597}\n",
            "{'predict_file_id': 61, 'predict_label': 'FREQUENCY', 'predict_start': 1070, 'predict_end': 1073, 'predict_text': 'p r n', 'start_char': 6233, 'end_char': 6238}\n",
            "{'predict_file_id': 62, 'predict_label': 'DRUG', 'predict_start': 2464, 'predict_end': 2465, 'predict_text': 'metoprolol', 'start_char': 13288, 'end_char': 13298}\n",
            "{'predict_file_id': 63, 'predict_label': 'DURATION', 'predict_start': 2144, 'predict_end': 2147, 'predict_text': 'for 7 days', 'start_char': 11882, 'end_char': 11892}\n",
            "{'predict_file_id': 64, 'predict_label': 'DRUG', 'predict_start': 2097, 'predict_end': 2098, 'predict_text': 'Tylenol', 'start_char': 11694, 'end_char': 11701}\n",
            "{'predict_file_id': 65, 'predict_label': 'DRUG', 'predict_start': 944, 'predict_end': 945, 'predict_text': 'antibotics', 'start_char': 5154, 'end_char': 5164}\n",
            "{'predict_file_id': 66, 'predict_label': 'DRUG', 'predict_start': 2002, 'predict_end': 2004, 'predict_text': 'psychiatric medications', 'start_char': 10993, 'end_char': 11016}\n",
            "{'predict_file_id': 67, 'predict_label': 'DRUG', 'predict_start': 3420, 'predict_end': 3421, 'predict_text': 'enoxaparin', 'start_char': 19186, 'end_char': 19196}\n",
            "{'predict_file_id': 68, 'predict_label': 'DRUG', 'predict_start': 1719, 'predict_end': 1720, 'predict_text': 'NORVASC', 'start_char': 9208, 'end_char': 9215}\n",
            "{'predict_file_id': 69, 'predict_label': 'FREQUENCY', 'predict_start': 2131, 'predict_end': 2133, 'predict_text': 'as needed', 'start_char': 11553, 'end_char': 11562}\n",
            "{'predict_file_id': 70, 'predict_label': 'FREQUENCY', 'predict_start': 2368, 'predict_end': 2374, 'predict_text': 'every eight 8 hours as needed', 'start_char': 13755, 'end_char': 13784}\n",
            "{'predict_file_id': 71, 'predict_label': 'FORM', 'predict_start': 2161, 'predict_end': 2162, 'predict_text': 'patches', 'start_char': 11692, 'end_char': 11699}\n",
            "{'predict_file_id': 72, 'predict_label': 'DRUG', 'predict_start': 4132, 'predict_end': 4133, 'predict_text': 'vancomycin', 'start_char': 21831, 'end_char': 21841}\n",
            "{'predict_file_id': 73, 'predict_label': 'DRUG', 'predict_start': 1138, 'predict_end': 1139, 'predict_text': 'pressor', 'start_char': 6642, 'end_char': 6649}\n",
            "{'predict_file_id': 74, 'predict_label': 'DRUG', 'predict_start': 598, 'predict_end': 599, 'predict_text': 'Versed', 'start_char': 3531, 'end_char': 3537}\n",
            "{'predict_file_id': 75, 'predict_label': 'DRUG', 'predict_start': 992, 'predict_end': 993, 'predict_text': 'Lasix', 'start_char': 6067, 'end_char': 6072}\n",
            "76\n",
            "11912\n",
            "       predict_file_id predict_label  predict_start  predict_end  \\\n",
            "0                    0          DRUG             21           22   \n",
            "1                    0          DRUG             22           25   \n",
            "2                    0          DRUG             25           26   \n",
            "3                    0          DRUG            115          116   \n",
            "4                    0      DURATION            117          120   \n",
            "...                ...           ...            ...          ...   \n",
            "11907               75     FREQUENCY            909          911   \n",
            "11908               75          DRUG            986          987   \n",
            "11909               75          DRUG            988          989   \n",
            "11910               75          DRUG            990          991   \n",
            "11911               75          DRUG            992          993   \n",
            "\n",
            "                        predict_text  start_char  end_char  \n",
            "0                        Penicillins         108       119  \n",
            "1      Sulfa Sulfonamide Antibiotics         120       149  \n",
            "2                           Lamictal         150       158  \n",
            "3                        Clindamycin         734       745  \n",
            "4                           1 28 wks         748       756  \n",
            "...                              ...         ...       ...  \n",
            "11907                          q day        5535      5540  \n",
            "11908                       Percocet        6038      6046  \n",
            "11909                         Motrin        6049      6055  \n",
            "11910                         Celexa        6058      6064  \n",
            "11911                          Lasix        6067      6072  \n",
            "\n",
            "[11912 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this code is to save the results of prediction in suitable format to calculate the confusion matrix of TP, FN, FP, TN\n",
        "# using type match (at least part of the token text is annotated with the correct entity type)\n",
        "# and using strict match (the token text and the entity type has to be matched the gold data)\n",
        "# COR: correct annotation of type\n",
        "# INC: incorrect annotation of type\n",
        "# MIS: missing annotation by Med7\n",
        "# SPU: Spurius is for a token predicted by Med7 with an entity label but it's not in the gold data\n",
        "\n",
        "# see this website explains NER evaluation:\n",
        "# https://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def processing(true_label_entity, predict_label_entity, name, path):\n",
        "\n",
        "  Eval = []\n",
        "\n",
        "  predict_label_entity_len = len(predict_label_entity)\n",
        "  type_list = []\n",
        "  strict_list = []\n",
        "  for i, row in true_label_entity.iterrows():\n",
        "    if i%500 == 0:\n",
        "\n",
        "      print(\"batch: \", i)\n",
        "    tmp = 0\n",
        "    for c, srow in predict_label_entity.iterrows():\n",
        "      #print(c)\n",
        "      if srow[0] > row[0]:\n",
        "        #print('LARGER', row[0], srow[0])\n",
        "        break\n",
        "      #if c%5000 == 0:\n",
        "        #print(\"batch c\", c)\n",
        "      Eval_dic = {}\n",
        "      if row[0] == srow[0]:\n",
        "        #print('EQUALS', row[0], srow[0])\n",
        "        if row[5] == srow[5] and row[6] == srow[6] and str(row[4]) == str(srow[4]):\n",
        "        #if str(row[4]).lower() == str(srow[4]).lower():\n",
        "          if str(row[1]).lower() == str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'COR'\n",
        "            Eval_dic['type_label'] = 'COR'\n",
        "            #print('str(row[4]).lower() == str(srow[4]).lower()', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            strict_list.append('COR')\n",
        "            type_list.append('COR')\n",
        "            #print(\"strict_list.append(COR), type_list.append(COR)\")\n",
        "            #true_label_entity = true_label_entity.drop([i])\n",
        "            #predict_label_entity = predict_label_entity.drop([c])\n",
        "            #predict_label_entity_len -= 1\n",
        "            #tmp = 1\n",
        "            #break\n",
        "          elif str(row[1]).lower() != str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'INC'\n",
        "            #print('str(row[4]).lower() == str(srow[4]).lower()', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            strict_list.append('INC')\n",
        "            type_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(INC)\")\n",
        "          true_label_entity = true_label_entity.drop([i])\n",
        "          predict_label_entity = predict_label_entity.drop([c])\n",
        "          predict_label_entity_len -= 1\n",
        "          tmp = 1\n",
        "          break\n",
        "\n",
        "        elif row[5] == srow[5] and str(row[4]) in str(srow[4]):\n",
        "          if str(row[1]).lower() == str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'COR'\n",
        "            #print('row[2] <= srow[2]', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            type_list.append('COR')\n",
        "            strict_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(COR)\")\n",
        "\n",
        "          elif str(row[1]).lower() != str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'INC'\n",
        "            #print('row[2] <= srow[2]', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            type_list.append('INC')\n",
        "            strict_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(INC)\")\n",
        "          #predict_label_entity = predict_label_entity.drop([c])\n",
        "          #predict_label_entity_len -= 1\n",
        "          #if row[3] < srow[3]:\n",
        "          true_label_entity = true_label_entity.drop([i])\n",
        "          tmp = 1\n",
        "\n",
        "\n",
        "        elif row[6] == srow[6] and str(row[4]) in str(srow[4]):\n",
        "          if str(row[1]).lower() == str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'COR'\n",
        "            #print('row[3] <= srow[3]', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            type_list.append('COR')\n",
        "            strict_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(COR)\")\n",
        "              #true_label_entity = true_label_entity.drop([i])\n",
        "\n",
        "              #break\n",
        "          elif str(row[1]).lower() != str(srow[1]).lower():\n",
        "              #print(\"equals\", i, c)\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'INC'\n",
        "            #print('row[3] <= srow[3]', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            type_list.append('INC')\n",
        "            strict_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(INC)\")\n",
        "              #true_label_entity = true_label_entity.drop([i])\n",
        "          predict_label_entity = predict_label_entity.drop([c])\n",
        "          predict_label_entity_len -= 1\n",
        "          true_label_entity = true_label_entity.drop([i])\n",
        "              #break\n",
        "          tmp = 1\n",
        "\n",
        "\n",
        "\n",
        "    if tmp == 0:\n",
        "      if i in true_label_entity.index:\n",
        "        Eval_dic = {}\n",
        "\n",
        "        Eval_dic['file_id'] = str(row[0])\n",
        "        Eval_dic['true_label'] = str(row[1]).lower()\n",
        "        Eval_dic['true_start'] = row[5]\n",
        "        Eval_dic['true_end'] = row[6]\n",
        "        Eval_dic['true_text'] = str(row[4])\n",
        "        Eval_dic['predict_file_id'] = str(srow[0])\n",
        "        Eval_dic['predict_label'] = \"O\"\n",
        "        Eval_dic['predict_start'] = row[5]\n",
        "        Eval_dic['predict_end'] = row[6]\n",
        "        Eval_dic['predict_text'] = str(row[4])\n",
        "        Eval_dic['strict_label'] = 'MIS'\n",
        "        Eval_dic['type_label'] = 'MIS'\n",
        "        Eval.append(Eval_dic)\n",
        "\n",
        "        #print(row)\n",
        "        strict_list.append('MIS')\n",
        "        type_list.append('MIS')\n",
        "        #print(\"strict_list.append(MIS), type_list.append(MIS)\")\n",
        "        true_label_entity = true_label_entity.drop([i])\n",
        "\n",
        "    #print(len(predict_label_entity), predict_label_entity_len)\n",
        "  for c, srow in predict_label_entity.iterrows():\n",
        "    #if len(predict_label_entity) > predict_label_entity_len:\n",
        "    Eval_dic = {}\n",
        "    Eval_dic['file_id'] = str(srow[0])\n",
        "    Eval_dic['true_label'] = 'O'\n",
        "    Eval_dic['true_start'] = srow[5]\n",
        "    Eval_dic['true_end'] = srow[6]\n",
        "    Eval_dic['true_text'] = str(srow[4])\n",
        "    Eval_dic['predict_file_id'] = str(srow[0])\n",
        "    Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "    Eval_dic['predict_start'] = srow[5]\n",
        "    Eval_dic['predict_end'] = srow[6]\n",
        "    Eval_dic['predict_text'] = str(srow[4])\n",
        "    Eval_dic['strict_label'] = 'SPU'\n",
        "    Eval_dic['type_label'] = 'SPU'\n",
        "    Eval.append(Eval_dic)\n",
        "    #print(srow)\n",
        "    strict_list.append('SPU')\n",
        "    type_list.append('SPU')\n",
        "    #print(\"strict_list.append(SPU), type_list.append(SPU)\")\n",
        "    predict_label_entity = predict_label_entity.drop([c])\n",
        "    predict_label_entity_len -= 1\n",
        "\n",
        "  true_predict_eval = pd.DataFrame.from_records(Eval)\n",
        "  print(len(true_predict_eval))\n",
        "  # uncomment this line to save the file, DO NOT FORGET TO CHANGE PATH AND FILE NAME\n",
        "  true_predict_eval.to_excel(path+'true_predict_label_entity_76testDataset_'+name+'.xlsx', index=False)  #true_predict_label_entity_76testDataset_en_core_med7_trf or true_predict_label_entity_76testDataset_en_core_med7_lg\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/collabrations_/HumanLoopH/Med7/data/\"\n",
        "\n",
        "true_label_entity = pd.read_excel(path+'gold_data_entity_CHoffsetEntitiesOnly_test_76.xlsx')\n",
        "print(true_label_entity)\n",
        "\n",
        "model = [\"en_core_med7_lg\", \"en_core_med7_trf\"]\n",
        "for name in model:\n",
        "  print(\"processing the output of \"+name+\" predictions over the testing set\")\n",
        "  predict_label_entity = pd.read_excel(path + 'predict_label_entity_76testDataset_'+name+'.xlsx') #predict_label_entity_76testDataset_en_core_med7_trf or predict_label_entity_76testDataset_en_core_med7_lg\n",
        "  print(predict_label_entity)\n",
        "  processing(true_label_entity, predict_label_entity, name, path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i2e_1GM7TCbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2411c8f5-55ef-4852-fddc-1dd84407847e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       file_id gold_label  token_start  token_end  \\\n",
            "0            0       Drug           21         22   \n",
            "1            0       Drug           22         25   \n",
            "2            0       Drug           25         26   \n",
            "3            0       Drug          115        116   \n",
            "4            0       Drug          124        125   \n",
            "...        ...        ...          ...        ...   \n",
            "12536       75  Frequency          909        911   \n",
            "12537       75       Drug          986        987   \n",
            "12538       75       Drug          988        989   \n",
            "12539       75       Drug          990        991   \n",
            "12540       75       Drug          992        993   \n",
            "\n",
            "                         entity_text  ch_start  ch_end  \n",
            "0                        Penicillins       108     119  \n",
            "1      Sulfa Sulfonamide Antibiotics       120     149  \n",
            "2                           Lamictal       150     158  \n",
            "3                        Clindamycin       734     745  \n",
            "4                           Levaquin       778     786  \n",
            "...                              ...       ...     ...  \n",
            "12536                          q day      5535    5540  \n",
            "12537                       Percocet      6038    6046  \n",
            "12538                         Motrin      6049    6055  \n",
            "12539                         Celexa      6058    6064  \n",
            "12540                          Lasix      6067    6072  \n",
            "\n",
            "[12541 rows x 7 columns]\n",
            "processing the output of en_core_med7_lg predictions over the testing set\n",
            "       predict_file_id predict_label  predict_start  predict_end predict_text  \\\n",
            "0                    0          DRUG             21           22  Penicillins   \n",
            "1                    0          DRUG            115          116  Clindamycin   \n",
            "2                    0        DOSAGE            117          118            1   \n",
            "3                    0          DRUG            124          125     Levaquin   \n",
            "4                    0          DRUG            126          127   Vancomycin   \n",
            "...                ...           ...            ...          ...          ...   \n",
            "12050               75          DRUG            986          987     Percocet   \n",
            "12051               75      STRENGTH            987          989     2 Motrin   \n",
            "12052               75        DOSAGE            989          990            3   \n",
            "12053               75          DRUG            990          991       Celexa   \n",
            "12054               75      STRENGTH            991          993      4 Lasix   \n",
            "\n",
            "       start_char  end_char  \n",
            "0             108       119  \n",
            "1             734       745  \n",
            "2             748       749  \n",
            "3             778       786  \n",
            "4             791       801  \n",
            "...           ...       ...  \n",
            "12050        6038      6046  \n",
            "12051        6047      6055  \n",
            "12052        6056      6057  \n",
            "12053        6058      6064  \n",
            "12054        6065      6072  \n",
            "\n",
            "[12055 rows x 7 columns]\n",
            "batch:  0\n",
            "batch:  500\n",
            "batch:  1000\n",
            "batch:  1500\n",
            "batch:  2000\n",
            "batch:  2500\n",
            "batch:  3000\n",
            "batch:  3500\n",
            "batch:  4000\n",
            "batch:  4500\n",
            "batch:  5000\n",
            "batch:  5500\n",
            "batch:  6000\n",
            "batch:  6500\n",
            "batch:  7000\n",
            "batch:  7500\n",
            "batch:  8000\n",
            "batch:  8500\n",
            "batch:  9000\n",
            "batch:  9500\n",
            "batch:  10000\n",
            "batch:  10500\n",
            "batch:  11000\n",
            "batch:  11500\n",
            "batch:  12000\n",
            "batch:  12500\n",
            "15976\n",
            "processing the output of en_core_med7_trf predictions over the testing set\n",
            "       predict_file_id predict_label  predict_start  predict_end  \\\n",
            "0                    0          DRUG             21           22   \n",
            "1                    0          DRUG             22           25   \n",
            "2                    0          DRUG             25           26   \n",
            "3                    0          DRUG            115          116   \n",
            "4                    0      DURATION            117          120   \n",
            "...                ...           ...            ...          ...   \n",
            "11907               75     FREQUENCY            909          911   \n",
            "11908               75          DRUG            986          987   \n",
            "11909               75          DRUG            988          989   \n",
            "11910               75          DRUG            990          991   \n",
            "11911               75          DRUG            992          993   \n",
            "\n",
            "                        predict_text  start_char  end_char  \n",
            "0                        Penicillins         108       119  \n",
            "1      Sulfa Sulfonamide Antibiotics         120       149  \n",
            "2                           Lamictal         150       158  \n",
            "3                        Clindamycin         734       745  \n",
            "4                           1 28 wks         748       756  \n",
            "...                              ...         ...       ...  \n",
            "11907                          q day        5535      5540  \n",
            "11908                       Percocet        6038      6046  \n",
            "11909                         Motrin        6049      6055  \n",
            "11910                         Celexa        6058      6064  \n",
            "11911                          Lasix        6067      6072  \n",
            "\n",
            "[11912 rows x 7 columns]\n",
            "batch:  0\n",
            "batch:  500\n",
            "batch:  1000\n",
            "batch:  1500\n",
            "batch:  2000\n",
            "batch:  2500\n",
            "batch:  3000\n",
            "batch:  3500\n",
            "batch:  4000\n",
            "batch:  4500\n",
            "batch:  5000\n",
            "batch:  5500\n",
            "batch:  6000\n",
            "batch:  6500\n",
            "batch:  7000\n",
            "batch:  7500\n",
            "batch:  8000\n",
            "batch:  8500\n",
            "batch:  9000\n",
            "batch:  9500\n",
            "batch:  10000\n",
            "batch:  10500\n",
            "batch:  11000\n",
            "batch:  11500\n",
            "batch:  12000\n",
            "batch:  12500\n",
            "14972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# This code is to calculate P, R, F1 scores based on matching the entity type between reference and candidate.\n",
        "# support in the output is the number of reference per entity type.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "def class_report(y_true, y_pred, path, name):\n",
        "\n",
        "  file = open(path+\"prediction_results_without_fine-tuning_\"+name+\".txt\", 'w')\n",
        "  labels = ['reason', 'ade', 'form', 'strength', 'dosage', 'drug', 'route', 'frequency', 'duration']\n",
        "  print(type(labels), labels)\n",
        "  report = classification_report(y_true, y_pred, labels = labels)\n",
        "  print(report)\n",
        "  file.writelines(report)\n",
        "\n",
        "  labels.remove('reason') # remove 'reason' label from evaluation\n",
        "  labels.remove('ade') # remove 'reason' label from evaluation\n",
        "  print(type(labels), labels)\n",
        "  report = classification_report(y_true, y_pred, labels = labels)\n",
        "  print(report)\n",
        "  file.writelines(report)\n",
        "  file.close()\n",
        "\n",
        "\n",
        "  #return report\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/collabrations_/HumanLoopH/Med7/data/\"\n",
        "model = [\"en_core_med7_lg\", \"en_core_med7_trf\"]\n",
        "for name in model:\n",
        "  print(\"caluculating P, R, F1 scores of \"+name+\" predictions over the testing set\")\n",
        "  eval_report_all = pd.read_excel(path+'true_predict_label_entity_76testDataset_'+name+'.xlsx') #predict_label_entity_76testDataset_en_core_med7_trf or predict_label_entity_76testDataset_en_core_med7_lg\n",
        "  print(\"76 Test dataset \"+name)\n",
        "  eval_report_copy_all = eval_report_all.copy()\n",
        "  y_true = eval_report_copy_all['true_label'].tolist()\n",
        "  y_pred = eval_report_copy_all['predict_label'].tolist()\n",
        "  print('type matching')\n",
        "  #all = class_report(y_true, y_pred)\n",
        "  class_report(y_true, y_pred, path, name)\n",
        "\n"
      ],
      "metadata": {
        "id": "FuBGQ2v14Z9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5d2657f-ea54-4815-bcc3-f14c6867d4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "caluculating P, R, F1 scores of en_core_med7_lg predictions over the testing set\n",
            "76 Test dataset en_core_med7_lg\n",
            "type matching\n",
            "<class 'list'> ['reason', 'ade', 'form', 'strength', 'dosage', 'drug', 'route', 'frequency', 'duration']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      reason       0.00      0.00      0.00       927\n",
            "         ade       0.00      0.00      0.00       242\n",
            "        form       0.90      0.90      0.90      1696\n",
            "    strength       0.70      0.80      0.75      1639\n",
            "      dosage       0.11      0.24      0.15      1039\n",
            "        drug       0.90      0.77      0.83      3954\n",
            "       route       0.96      0.94      0.94      1341\n",
            "   frequency       0.74      0.79      0.76      1564\n",
            "    duration       0.73      0.75      0.74       139\n",
            "\n",
            "   micro avg       0.71      0.69      0.70     12541\n",
            "   macro avg       0.56      0.58      0.56     12541\n",
            "weighted avg       0.71      0.69      0.70     12541\n",
            "\n",
            "<class 'list'> ['form', 'strength', 'dosage', 'drug', 'route', 'frequency', 'duration']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        form       0.90      0.90      0.90      1696\n",
            "    strength       0.70      0.80      0.75      1639\n",
            "      dosage       0.11      0.24      0.15      1039\n",
            "        drug       0.90      0.77      0.83      3954\n",
            "       route       0.96      0.94      0.94      1341\n",
            "   frequency       0.74      0.79      0.76      1564\n",
            "    duration       0.73      0.75      0.74       139\n",
            "\n",
            "   micro avg       0.71      0.77      0.74     11372\n",
            "   macro avg       0.72      0.74      0.72     11372\n",
            "weighted avg       0.78      0.77      0.77     11372\n",
            "\n",
            "caluculating P, R, F1 scores of en_core_med7_trf predictions over the testing set\n",
            "76 Test dataset en_core_med7_trf\n",
            "type matching\n",
            "<class 'list'> ['reason', 'ade', 'form', 'strength', 'dosage', 'drug', 'route', 'frequency', 'duration']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      reason       0.00      0.00      0.00       927\n",
            "         ade       0.00      0.00      0.00       242\n",
            "        form       0.84      0.93      0.88      1696\n",
            "    strength       0.70      0.79      0.74      1639\n",
            "      dosage       0.28      0.42      0.34      1039\n",
            "        drug       0.95      0.90      0.92      3954\n",
            "       route       0.95      0.96      0.96      1341\n",
            "   frequency       0.80      0.80      0.80      1564\n",
            "    duration       0.79      0.86      0.83       139\n",
            "\n",
            "   micro avg       0.79      0.76      0.77     12541\n",
            "   macro avg       0.59      0.63      0.61     12541\n",
            "weighted avg       0.74      0.76      0.75     12541\n",
            "\n",
            "<class 'list'> ['form', 'strength', 'dosage', 'drug', 'route', 'frequency', 'duration']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        form       0.84      0.93      0.88      1696\n",
            "    strength       0.70      0.79      0.74      1639\n",
            "      dosage       0.28      0.42      0.34      1039\n",
            "        drug       0.95      0.90      0.92      3954\n",
            "       route       0.95      0.96      0.96      1341\n",
            "   frequency       0.80      0.80      0.80      1564\n",
            "    duration       0.79      0.86      0.83       139\n",
            "\n",
            "   micro avg       0.79      0.84      0.81     11372\n",
            "   macro avg       0.76      0.81      0.78     11372\n",
            "weighted avg       0.81      0.84      0.82     11372\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this code is to fine-tune Med7 with two versions\n",
        "#en_core_med7_trf en_core_med7_lg\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy import util\n",
        "from spacy.tokens import Doc\n",
        "from spacy.training import Example\n",
        "from spacy.tokens import DocBin\n",
        "from spacy.language import Language\n",
        "\n",
        "\n",
        "def customizing_pipeline_component(path, nlp: Language, offset, name):\n",
        "    file = open(path+\"loss_log.txt\", \"w\")\n",
        "\n",
        "    #optimizer = nlp.create_optimizer()\n",
        "    optimizer = nlp.resume_training()\n",
        "    print(type(offset), len(offset))\n",
        "    print(\"   Training ...\")\n",
        "    # setup the number of iterations here\n",
        "    iter = 2\n",
        "    file.writelines(\"post-training \" + name + \"for \" + str(iter) + \"iterations\\n\")\n",
        "    for _ in range(iter):\n",
        "        print(\"iteration: \" + str(_))\n",
        "        random.shuffle(offset)\n",
        "        losses = {}\n",
        "        for raw_text, entity_offsets in offset: # add character indexes\n",
        "            entities = spacy.training.offsets_to_biluo_tags(nlp.make_doc(raw_text), entity_offsets)\n",
        "            #print(entities)\n",
        "            doc = nlp.make_doc(raw_text)\n",
        "            example = Example.from_dict(doc, {\"entities\": entity_offsets})\n",
        "            #print('[example]', len([example]))\n",
        "            nlp.update([example], sgd=optimizer, losses=losses)\n",
        "        print(_, losses)\n",
        "        file.writelines(\"iteration: \"+ str(_) + str(losses)+\"\\n\")\n",
        "    file.close()\n",
        "    # save the post-trained model\n",
        "    nlp.to_disk(path + name +\"_plus\")\n",
        "\n",
        "    # Result after training\n",
        "    print(f\"Result AFTER training:\")\n",
        "    df = pd.read_json(path + \"test_76.json\", lines=True)\n",
        "\n",
        "    predict_labels_lg_dic = []\n",
        "\n",
        "    for i, token in enumerate(df.tokens.to_list()):\n",
        "      token_str_lg = ' '.join(str(t) for t in token)\n",
        "\n",
        "      entities = nlp(token_str_lg)\n",
        "      for e in entities.ents:\n",
        "        predict_dic = {}\n",
        "        predict_dic[\"predict_file_id\"] = i\n",
        "        predict_dic['predict_label'] = e.label_\n",
        "        predict_dic['predict_start'] = e.start\n",
        "        predict_dic['predict_end'] = e.end\n",
        "        predict_dic['predict_text'] = e.text\n",
        "        predict_dic['start_char'] = e.start_char\n",
        "        predict_dic['end_char'] = e.end_char\n",
        "\n",
        "        predict_labels_lg_dic.append(predict_dic)\n",
        "      print('file_id:', i)\n",
        "\n",
        "    print(len(predict_labels_lg_dic))\n",
        "    predict_label_entity = pd.DataFrame.from_records(predict_labels_lg_dic)\n",
        "    print(predict_label_entity)\n",
        "\n",
        "    # uncomment to save the output of the prediction after fine-tuning MED7\n",
        "    predict_label_entity.to_excel(path + 'test_76_'+name+'_fine_tuned_'+str(iter)+'iterations.xlsx', index=False)\n",
        "\n",
        "def main():\n",
        "    input_dir = \"/content/drive/MyDrive/collabrations_/HumanLoopH/Med7/data/\"\n",
        "    print(\"read data\")\n",
        "    json = pd.read_json(input_dir + \"train_validation_429.json\", lines=True)\n",
        "    excel = pd.read_excel(input_dir + 'gold_data_entity_CHoffsetEntitiesOnly_train_validation_429.xlsx')\n",
        "    input_annotations_all = []\n",
        "    print(\"processing data\")\n",
        "    for i, token in enumerate(json.tokens.to_list()):\n",
        "      input_annotations = []\n",
        "      # create one discharge summary with its NER labels\n",
        "      token_str_lg = ' '.join(str(t) for t in token)\n",
        "      file_id =  excel[excel['file_id'] == i]\n",
        "      for i, row in file_id.iterrows():\n",
        "        input_annotations.append((int(row[5]), int(row[6]), row[1])) #(start, end, label)\n",
        "      input_annotations_all.append([token_str_lg, input_annotations])\n",
        "    print(\"post-training en_core_med7_lg\")\n",
        "    med7 = spacy.load(\"en_core_med7_lg\")\n",
        "    customizing_pipeline_component(input_dir, med7, input_annotations_all, \"en_core_med7_lg\")\n",
        "\n",
        "    # uncomment th elines below to fine-tune \"en_core_med7_trf\"\n",
        "    print(\"post-training en_core_med7_trf\")\n",
        "    med7 = spacy.load(\"en_core_med7_trf\")\n",
        "    customizing_pipeline_component(input_dir, med7, input_annotations_all, \"en_core_med7_trf\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "nYssmDPcdPcy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4f6bc057-207d-4a3a-a993-c1e228889ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "read data\n",
            "processing data\n",
            "post-training en_core_med7_lg\n",
            "<class 'list'> 429\n",
            "   Training ...\n",
            "iteration: 0\n",
            "0 {'tok2vec': 1604935.530559482, 'ner': 37516.963444490735}\n",
            "iteration: 1\n",
            "1 {'tok2vec': 28759.0993615943, 'ner': 20903.504677825662}\n",
            "Result AFTER training:\n",
            "file_id: 0\n",
            "file_id: 1\n",
            "file_id: 2\n",
            "file_id: 3\n",
            "file_id: 4\n",
            "file_id: 5\n",
            "file_id: 6\n",
            "file_id: 7\n",
            "file_id: 8\n",
            "file_id: 9\n",
            "file_id: 10\n",
            "file_id: 11\n",
            "file_id: 12\n",
            "file_id: 13\n",
            "file_id: 14\n",
            "file_id: 15\n",
            "file_id: 16\n",
            "file_id: 17\n",
            "file_id: 18\n",
            "file_id: 19\n",
            "file_id: 20\n",
            "file_id: 21\n",
            "file_id: 22\n",
            "file_id: 23\n",
            "file_id: 24\n",
            "file_id: 25\n",
            "file_id: 26\n",
            "file_id: 27\n",
            "file_id: 28\n",
            "file_id: 29\n",
            "file_id: 30\n",
            "file_id: 31\n",
            "file_id: 32\n",
            "file_id: 33\n",
            "file_id: 34\n",
            "file_id: 35\n",
            "file_id: 36\n",
            "file_id: 37\n",
            "file_id: 38\n",
            "file_id: 39\n",
            "file_id: 40\n",
            "file_id: 41\n",
            "file_id: 42\n",
            "file_id: 43\n",
            "file_id: 44\n",
            "file_id: 45\n",
            "file_id: 46\n",
            "file_id: 47\n",
            "file_id: 48\n",
            "file_id: 49\n",
            "file_id: 50\n",
            "file_id: 51\n",
            "file_id: 52\n",
            "file_id: 53\n",
            "file_id: 54\n",
            "file_id: 55\n",
            "file_id: 56\n",
            "file_id: 57\n",
            "file_id: 58\n",
            "file_id: 59\n",
            "file_id: 60\n",
            "file_id: 61\n",
            "file_id: 62\n",
            "file_id: 63\n",
            "file_id: 64\n",
            "file_id: 65\n",
            "file_id: 66\n",
            "file_id: 67\n",
            "file_id: 68\n",
            "file_id: 69\n",
            "file_id: 70\n",
            "file_id: 71\n",
            "file_id: 72\n",
            "file_id: 73\n",
            "file_id: 74\n",
            "file_id: 75\n",
            "11722\n",
            "       predict_file_id predict_label  predict_start  predict_end predict_text  \\\n",
            "0                    0          Drug             21           22  Penicillins   \n",
            "1                    0          Drug             22           23        Sulfa   \n",
            "2                    0          Drug             25           26     Lamictal   \n",
            "3                    0          Drug            115          116  Clindamycin   \n",
            "4                    0        Dosage            117          118            1   \n",
            "...                ...           ...            ...          ...          ...   \n",
            "11717               75          Drug            988          989       Motrin   \n",
            "11718               75      Strength            989          990            3   \n",
            "11719               75          Drug            990          991       Celexa   \n",
            "11720               75      Strength            991          992            4   \n",
            "11721               75          Drug            992          993        Lasix   \n",
            "\n",
            "       start_char  end_char  \n",
            "0             108       119  \n",
            "1             120       125  \n",
            "2             150       158  \n",
            "3             734       745  \n",
            "4             748       749  \n",
            "...           ...       ...  \n",
            "11717        6049      6055  \n",
            "11718        6056      6057  \n",
            "11719        6058      6064  \n",
            "11720        6065      6066  \n",
            "11721        6067      6072  \n",
            "\n",
            "[11722 rows x 7 columns]\n",
            "post-training en_core_med7_trf\n",
            "<class 'list'> 429\n",
            "   Training ...\n",
            "iteration: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# same code as above\n",
        "# this code is to save the results of prediction in suitable format to calculate the confusion matrix of TP, FN, FP, TN\n",
        "# using type match (at least part of the token text is annotated with the correct entity type)\n",
        "# and using strict match (the token text and the entity type has to be matched the gold data)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def processing(true_label_entity, predict_label_entity, name, path):\n",
        "\n",
        "  Eval = []\n",
        "\n",
        "  predict_label_entity_len = len(predict_label_entity)\n",
        "  type_list = []\n",
        "  strict_list = []\n",
        "  for i, row in true_label_entity.iterrows():\n",
        "    if i%500 == 0:\n",
        "\n",
        "      print(\"batch: \", i)\n",
        "    tmp = 0\n",
        "    for c, srow in predict_label_entity.iterrows():\n",
        "      #print(c)\n",
        "      if srow[0] > row[0]:\n",
        "        #print('LARGER', row[0], srow[0])\n",
        "        break\n",
        "      #if c%5000 == 0:\n",
        "        #print(\"batch c\", c)\n",
        "      Eval_dic = {}\n",
        "      if row[0] == srow[0]:\n",
        "        #print('EQUALS', row[0], srow[0])\n",
        "        if row[5] == srow[5] and row[6] == srow[6] and str(row[4]) == str(srow[4]):\n",
        "        #if str(row[4]).lower() == str(srow[4]).lower():\n",
        "          if str(row[1]).lower() == str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'COR'\n",
        "            Eval_dic['type_label'] = 'COR'\n",
        "            #print('str(row[4]).lower() == str(srow[4]).lower()', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            strict_list.append('COR')\n",
        "            type_list.append('COR')\n",
        "            #print(\"strict_list.append(COR), type_list.append(COR)\")\n",
        "            #true_label_entity = true_label_entity.drop([i])\n",
        "            #predict_label_entity = predict_label_entity.drop([c])\n",
        "            #predict_label_entity_len -= 1\n",
        "            #tmp = 1\n",
        "            #break\n",
        "          elif str(row[1]).lower() != str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'INC'\n",
        "            #print('str(row[4]).lower() == str(srow[4]).lower()', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            strict_list.append('INC')\n",
        "            type_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(INC)\")\n",
        "          true_label_entity = true_label_entity.drop([i])\n",
        "          predict_label_entity = predict_label_entity.drop([c])\n",
        "          predict_label_entity_len -= 1\n",
        "          tmp = 1\n",
        "          break\n",
        "\n",
        "        elif row[5] == srow[5] and str(row[4]) in str(srow[4]):\n",
        "          if str(row[1]).lower() == str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'COR'\n",
        "            #print('row[2] <= srow[2]', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            type_list.append('COR')\n",
        "            strict_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(COR)\")\n",
        "\n",
        "          elif str(row[1]).lower() != str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'INC'\n",
        "            #print('row[2] <= srow[2]', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            type_list.append('INC')\n",
        "            strict_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(INC)\")\n",
        "          #predict_label_entity = predict_label_entity.drop([c])\n",
        "          #predict_label_entity_len -= 1\n",
        "          #if row[3] < srow[3]:\n",
        "          true_label_entity = true_label_entity.drop([i])\n",
        "          tmp = 1\n",
        "\n",
        "\n",
        "        elif row[6] == srow[6] and str(row[4]) in str(srow[4]):\n",
        "          if str(row[1]).lower() == str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'COR'\n",
        "            #print('row[3] <= srow[3]', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            type_list.append('COR')\n",
        "            strict_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(COR)\")\n",
        "              #true_label_entity = true_label_entity.drop([i])\n",
        "\n",
        "              #break\n",
        "          elif str(row[1]).lower() != str(srow[1]).lower():\n",
        "              #print(\"equals\", i, c)\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'INC'\n",
        "            #print('row[3] <= srow[3]', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            type_list.append('INC')\n",
        "            strict_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(INC)\")\n",
        "              #true_label_entity = true_label_entity.drop([i])\n",
        "          predict_label_entity = predict_label_entity.drop([c])\n",
        "          predict_label_entity_len -= 1\n",
        "          true_label_entity = true_label_entity.drop([i])\n",
        "              #break\n",
        "          tmp = 1\n",
        "\n",
        "\n",
        "\n",
        "    if tmp == 0:\n",
        "      if i in true_label_entity.index:\n",
        "        Eval_dic = {}\n",
        "\n",
        "        Eval_dic['file_id'] = str(row[0])\n",
        "        Eval_dic['true_label'] = str(row[1]).lower()\n",
        "        Eval_dic['true_start'] = row[5]\n",
        "        Eval_dic['true_end'] = row[6]\n",
        "        Eval_dic['true_text'] = str(row[4])\n",
        "        Eval_dic['predict_file_id'] = str(srow[0])\n",
        "        Eval_dic['predict_label'] = \"O\"\n",
        "        Eval_dic['predict_start'] = row[5]\n",
        "        Eval_dic['predict_end'] = row[6]\n",
        "        Eval_dic['predict_text'] = str(row[4])\n",
        "        Eval_dic['strict_label'] = 'MIS'\n",
        "        Eval_dic['type_label'] = 'MIS'\n",
        "        Eval.append(Eval_dic)\n",
        "\n",
        "        #print(row)\n",
        "        strict_list.append('MIS')\n",
        "        type_list.append('MIS')\n",
        "        #print(\"strict_list.append(MIS), type_list.append(MIS)\")\n",
        "        true_label_entity = true_label_entity.drop([i])\n",
        "\n",
        "    #print(len(predict_label_entity), predict_label_entity_len)\n",
        "  for c, srow in predict_label_entity.iterrows():\n",
        "    #if len(predict_label_entity) > predict_label_entity_len:\n",
        "    Eval_dic = {}\n",
        "    Eval_dic['file_id'] = str(srow[0])\n",
        "    Eval_dic['true_label'] = 'O'\n",
        "    Eval_dic['true_start'] = srow[5]\n",
        "    Eval_dic['true_end'] = srow[6]\n",
        "    Eval_dic['true_text'] = str(srow[4])\n",
        "    Eval_dic['predict_file_id'] = str(srow[0])\n",
        "    Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "    Eval_dic['predict_start'] = srow[5]\n",
        "    Eval_dic['predict_end'] = srow[6]\n",
        "    Eval_dic['predict_text'] = str(srow[4])\n",
        "    Eval_dic['strict_label'] = 'SPU'\n",
        "    Eval_dic['type_label'] = 'SPU'\n",
        "    Eval.append(Eval_dic)\n",
        "    #print(srow)\n",
        "    strict_list.append('SPU')\n",
        "    type_list.append('SPU')\n",
        "    #print(\"strict_list.append(SPU), type_list.append(SPU)\")\n",
        "    predict_label_entity = predict_label_entity.drop([c])\n",
        "    predict_label_entity_len -= 1\n",
        "\n",
        "  true_predict_eval = pd.DataFrame.from_records(Eval)\n",
        "  print(len(true_predict_eval))\n",
        "  # if you changed the number of iterations to other than 30 change it in the line below\n",
        "#  true_predict_eval.to_excel(path+'true_predict_label_entity_76testDataset_'+name+'_fine_tuned_30iterations.xlsx', index=False)  #true_predict_label_entity_76testDataset_en_core_med7_trf or true_predict_label_entity_76testDataset_en_core_med7_lg\n",
        "  true_predict_eval.to_excel(path+'true_predict_label_entity_76testDataset_'+name+'_fine_tuned_2iterations.xlsx', index=False)  #true_predict_label_entity_76testDataset_en_core_med7_trf or true_predict_label_entity_76testDataset_en_core_med7_lg\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/collabrations_/HumanLoopH/Med7/data/\"\n",
        "\n",
        "true_label_entity = pd.read_excel(path+'gold_data_entity_CHoffsetEntitiesOnly_test_76.xlsx')\n",
        "print(true_label_entity)\n",
        "\n",
        "#model = [\"en_core_med7_lg\", \"en_core_med7_trf\"]\n",
        "model = [\"en_core_med7_lg\"]\n",
        "for name in model:\n",
        "  print(\"processing the output of \"+name+\" predictions over the testing set\")\n",
        "\n",
        "  # make sure the number of iterations is correct in the file name\n",
        "  # if you changed the number of iterations to other than 30 change it in the line below\n",
        "#  predict_label_entity = pd.read_excel(path + 'test_76_'+name+'_fine_tuned_30iterations.xlsx') #predict_label_entity_76testDataset_en_core_med7_trf or predict_label_entity_76testDataset_en_core_med7_lg\n",
        "  predict_label_entity = pd.read_excel(path + 'test_76_'+name+'_fine_tuned_2iterations.xlsx') #predict_label_entity_76testDataset_en_core_med7_trf or predict_label_entity_76testDataset_en_core_med7_lg\n",
        "  print(predict_label_entity)\n",
        "  processing(true_label_entity, predict_label_entity, name, path)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fuzJRKAPvgfD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "00813858-721f-4867-d706-2e4c4a69f80c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       file_id gold_label  token_start  token_end  \\\n",
            "0            0       Drug           21         22   \n",
            "1            0       Drug           22         25   \n",
            "2            0       Drug           25         26   \n",
            "3            0       Drug          115        116   \n",
            "4            0       Drug          124        125   \n",
            "...        ...        ...          ...        ...   \n",
            "12536       75  Frequency          909        911   \n",
            "12537       75       Drug          986        987   \n",
            "12538       75       Drug          988        989   \n",
            "12539       75       Drug          990        991   \n",
            "12540       75       Drug          992        993   \n",
            "\n",
            "                         entity_text  ch_start  ch_end  \n",
            "0                        Penicillins       108     119  \n",
            "1      Sulfa Sulfonamide Antibiotics       120     149  \n",
            "2                           Lamictal       150     158  \n",
            "3                        Clindamycin       734     745  \n",
            "4                           Levaquin       778     786  \n",
            "...                              ...       ...     ...  \n",
            "12536                          q day      5535    5540  \n",
            "12537                       Percocet      6038    6046  \n",
            "12538                         Motrin      6049    6055  \n",
            "12539                         Celexa      6058    6064  \n",
            "12540                          Lasix      6067    6072  \n",
            "\n",
            "[12541 rows x 7 columns]\n",
            "processing the output of en_core_med7_lg predictions over the testing set\n",
            "       predict_file_id predict_label  predict_start  predict_end predict_text  \\\n",
            "0                    0          Drug             21           22  Penicillins   \n",
            "1                    0          Drug             22           23        Sulfa   \n",
            "2                    0          Drug             25           26     Lamictal   \n",
            "3                    0          Drug            115          116  Clindamycin   \n",
            "4                    0        Dosage            117          118            1   \n",
            "...                ...           ...            ...          ...          ...   \n",
            "11717               75          Drug            988          989       Motrin   \n",
            "11718               75      Strength            989          990            3   \n",
            "11719               75          Drug            990          991       Celexa   \n",
            "11720               75      Strength            991          992            4   \n",
            "11721               75          Drug            992          993        Lasix   \n",
            "\n",
            "       start_char  end_char  \n",
            "0             108       119  \n",
            "1             120       125  \n",
            "2             150       158  \n",
            "3             734       745  \n",
            "4             748       749  \n",
            "...           ...       ...  \n",
            "11717        6049      6055  \n",
            "11718        6056      6057  \n",
            "11719        6058      6064  \n",
            "11720        6065      6066  \n",
            "11721        6067      6072  \n",
            "\n",
            "[11722 rows x 7 columns]\n",
            "batch:  0\n",
            "batch:  500\n",
            "batch:  1000\n",
            "batch:  1500\n",
            "batch:  2000\n",
            "batch:  2500\n",
            "batch:  3000\n",
            "batch:  3500\n",
            "batch:  4000\n",
            "batch:  4500\n",
            "batch:  5000\n",
            "batch:  5500\n",
            "batch:  6000\n",
            "batch:  6500\n",
            "batch:  7000\n",
            "batch:  7500\n",
            "batch:  8000\n",
            "batch:  8500\n",
            "batch:  9000\n",
            "batch:  9500\n",
            "batch:  10000\n",
            "batch:  10500\n",
            "batch:  11000\n",
            "batch:  11500\n",
            "batch:  12000\n",
            "batch:  12500\n",
            "13386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# same code as above\n",
        "# This code is to calculate P, R, F1 scores based on matching the entity type between reference and candidate.\n",
        "# support in the output is the number of reference per entity type.\n",
        "\n",
        "# DONOT FORGET TO CHANGE PATHS AND FILES NAMES\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "def class_report(y_true, y_pred, path, name):\n",
        "\n",
        "  file = open(path+\"prediction_results_after_fine-tuning_\"+name+\".txt\", 'w')\n",
        "  labels = ['reason', 'ade', 'form', 'strength', 'dosage', 'drug', 'route', 'frequency', 'duration']\n",
        "  print(type(labels), labels)\n",
        "  report = classification_report(y_true, y_pred, labels = labels)\n",
        "  print(report)\n",
        "  file.writelines(report)\n",
        "\n",
        "  labels.remove('reason') # remove 'reason' label from evaluation\n",
        "  labels.remove('ade') # remove 'reason' label from evaluation\n",
        "  print(type(labels), labels)\n",
        "  report = classification_report(y_true, y_pred, labels = labels)\n",
        "  print(report)\n",
        "  file.writelines(report)\n",
        "  file.close()\n",
        "\n",
        "\n",
        "  #return report\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/collabrations_/HumanLoopH/Med7/data/\"\n",
        "#model = [\"en_core_med7_lg\", \"en_core_med7_trf\"]\n",
        "model = [\"en_core_med7_lg\"]\n",
        "for name in model:\n",
        "#  print(\"caluculating P, R, F1 scores of \"+name+\" predictions over the testing set AFTER fine-tuning on 429 n2c2-2018 training set with 30 iterations\")\n",
        "#  eval_report_all = pd.read_excel(path+'true_predict_label_entity_76testDataset_'+name+'_fine_tuned_30iterations.xlsx') #predict_label_entity_76testDataset_en_core_med7_trf or predict_label_entity_76testDataset_en_core_med7_lg\n",
        "  print(\"caluculating P, R, F1 scores of \"+name+\" predictions over the testing set AFTER fine-tuning on 429 n2c2-2018 training set with 2 iterations\")\n",
        "  eval_report_all = pd.read_excel(path+'true_predict_label_entity_76testDataset_'+name+'_fine_tuned_2iterations.xlsx') #predict_label_entity_76testDataset_en_core_med7_trf or predict_label_entity_76testDataset_en_core_med7_lg\n",
        "  print(\"76 Test dataset \"+name)\n",
        "  eval_report_copy_all = eval_report_all.copy()\n",
        "  y_true = eval_report_copy_all['true_label'].tolist()\n",
        "  y_pred = eval_report_copy_all['predict_label'].tolist()\n",
        "  print('type matching')\n",
        "  #all = class_report(y_true, y_pred)\n",
        "  class_report(y_true, y_pred, path, name)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZzgYJNAkwIao",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "87d7f233-51fd-4dd3-db8d-e3772f63bd23"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "caluculating P, R, F1 scores of en_core_med7_lg predictions over the testing set AFTER fine-tuning on 429 n2c2-2018 training set with 2 iterations\n",
            "76 Test dataset en_core_med7_lg\n",
            "type matching\n",
            "<class 'list'> ['reason', 'ade', 'form', 'strength', 'dosage', 'drug', 'route', 'frequency', 'duration']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      reason       0.78      0.37      0.50       927\n",
            "         ade       0.86      0.05      0.09       242\n",
            "        form       0.94      0.95      0.95      1696\n",
            "    strength       0.95      0.97      0.96      1639\n",
            "      dosage       0.90      0.93      0.91      1039\n",
            "        drug       0.93      0.93      0.93      3954\n",
            "       route       0.96      0.95      0.95      1341\n",
            "   frequency       0.85      0.95      0.90      1564\n",
            "    duration       0.88      0.58      0.70       139\n",
            "\n",
            "   micro avg       0.92      0.88      0.90     12541\n",
            "   macro avg       0.89      0.74      0.77     12541\n",
            "weighted avg       0.91      0.88      0.88     12541\n",
            "\n",
            "<class 'list'> ['form', 'strength', 'dosage', 'drug', 'route', 'frequency', 'duration']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        form       0.94      0.95      0.95      1696\n",
            "    strength       0.95      0.97      0.96      1639\n",
            "      dosage       0.90      0.93      0.91      1039\n",
            "        drug       0.93      0.93      0.93      3954\n",
            "       route       0.96      0.95      0.95      1341\n",
            "   frequency       0.85      0.95      0.90      1564\n",
            "    duration       0.88      0.58      0.70       139\n",
            "\n",
            "   micro avg       0.92      0.94      0.93     11372\n",
            "   macro avg       0.92      0.90      0.90     11372\n",
            "weighted avg       0.92      0.94      0.93     11372\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All code below is for pre-process Brat annotaion (NER)\n",
        "# skip if you don't need"
      ],
      "metadata": {
        "id": "HndqlNj91zEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkmE9ECUMYt7"
      },
      "outputs": [],
      "source": [
        "!python /content/drive/MyDrive/Reasearch_Assistantship/HILO_project/brat2CoNLL-main/brat2CoNLL/format_convertor2.py --input_dir=/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/train --output_file=/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/train/output/output.txt\n",
        "!python /content/drive/MyDrive/Reasearch_Assistantship/HILO_project/brat2CoNLL-main/brat2CoNLL/format_convertor2.py --input_dir=/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/valid --output_file=/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/valid/output/output.txt\n",
        "!python /content/drive/MyDrive/Reasearch_Assistantship/HILO_project/brat2CoNLL-main/brat2CoNLL/format_convertor2.py --input_dir=/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/test --output_file=/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/test/output/output.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Edit pre-process\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/train/output/output.xlsx')\n",
        "print(df.columns)\n",
        "\n",
        "df_copy = df.copy()\n",
        "line = df_copy.index[df_copy['Unnamed: 2'] == \"O\"].tolist()\n",
        "print(len(df_copy))\n",
        "print(len(line))\n",
        "df2 = pd.DataFrame(columns = ['Token', 'Label', 'Unnamed: 2'])\n",
        "for id in line:\n",
        "  tmp = df_copy.iloc[id]\n",
        "  #print(tmp[2])\n",
        "\n",
        "  test = pd.DataFrame({'Token' : tmp[0], 'Label' : tmp[2], 'Unnamed: 2' : pd.NA}, index=[id])\n",
        "  df2 = pd.concat([df2, test], axis=0, ignore_index=False)\n",
        "  #df2 = df2.append(test, ignore_index=False)\n",
        "  test = pd.DataFrame({'Token' : tmp[1], 'Label' : tmp[2], 'Unnamed: 2' : pd.NA}, index=[id+1])\n",
        "  df2 = pd.concat([df2, test], axis=0, ignore_index=False)\n",
        "  #df2 = df2.append(test, ignore_index=False)\n",
        "\n",
        "  #print(tmp)\n",
        "print(len(df2))\n",
        "print(df_copy.loc[[29490]])\n",
        "df_copy = df_copy.drop(line)\n",
        "print(len(df_copy))\n",
        "line = df2.iloc[0]\n",
        "print(line)\n",
        "line = df2.iloc[1]\n",
        "print(line)\n",
        "# https://huggingface.co/course/chapter7/2\n",
        "df3 = pd.concat([df2, df_copy], axis=0)\n",
        "print(df3)\n",
        "df3.to_excel('/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/train/output/output2.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "OAqHko1_AXPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split all discharge sammaries into seperate files, a file for a discharge summary\n",
        "\n",
        "df = pd.read_excel('/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/valid/output/output.xlsx', index=False)\n",
        "print(len(df))\n",
        "print(df.columns)\n",
        "\n",
        "df_copy = df.copy()\n",
        "line = []\n",
        "for i, row in df_copy.iterrows():\n",
        "  #print(i, row[0], row[1])\n",
        "  if \".txt\" in row[1]:\n",
        "    print(i, row[0], row[1])\n",
        "    line.append(i)\n",
        "print(len(line))\n",
        "print(line)\n",
        "i = 0\n",
        "while i+1 <= len(line):\n",
        "  if i+1 == len(line):\n",
        "    df_slice = df_copy.iloc[line[i]:len(df_copy), :]\n",
        "    txt_ind = df_slice[\"Label\"].tolist()\n",
        "    print(txt_ind[0])\n",
        "    df_slice.to_excel('/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/valid/output/'+txt_ind[0]+'.xlsx', index=False)\n",
        "  else:\n",
        "    df_slice = df_copy.iloc[line[i]:line[i+1], :]\n",
        "    txt_ind = df_slice[\"Label\"].tolist()\n",
        "    print(txt_ind[0])\n",
        "    df_slice.to_excel('/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/valid/output/'+txt_ind[0]+'.xlsx', index=False)\n",
        "  i +=1"
      ],
      "metadata": {
        "id": "fCfhUrmQhL_f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}