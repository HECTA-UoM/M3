{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# for references\n",
        "#https://spacy.io/usage/processing-pipelines#sourced-components\n",
        "#https://spacy.io/api/doc\n",
        "#https://spacy.io/usage/training\n",
        "#https://spacy.io/usage/saving-loading\n",
        "# https://stackoverflow.com/questions/69181078/spacy-how-do-you-add-custom-ner-labels-to-a-pre-trained-model\n"
      ],
      "metadata": {
        "id": "thomwkubzIeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "jLaUu6jCwTra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installing Med7 (GLOVE and roberta embeddings) and it's related libraries\n",
        "!python -m pip install jedi\n",
        "!python -m pip install -U wheel pip setuptools pip install spacy==3.4.4 pip install spacy-transformers==1.1.9\n",
        "!python -m pip install https://huggingface.co/kormilitzin/en_core_med7_lg/resolve/main/en_core_med7_lg-any-py3-none-any.whl\n",
        "!python -m pip install https://huggingface.co/kormilitzin/en_core_med7_trf/resolve/main/en_core_med7_trf-any-py3-none-any.whl"
      ],
      "metadata": {
        "id": "Pjr63EN-NM9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT FORGET TO CHANGE THE PATHS AND THE FILES NAMES\n",
        "\n",
        "# this code is to read bert data format (tokens, ner_tags, input_ids, attention_mask, labels)\n",
        "# and change the data format to character offset for spacy ner model\n",
        "# it generate  an excel file with all the tokens in the discharge summary that are labelled as entities only.\n",
        "# you can edit the code to generate an excel file with all the tokens in the discharge summary, either an entity or not\n",
        "# by uncommenting line No 34 \"gold_data.append(gold_data_dic)\"\n",
        "\n",
        "import pandas as pd\n",
        "def preprocess(df, name, path):\n",
        "  gold_data_entities = []\n",
        "  gold_data_tokens = []\n",
        "  for i, tags in enumerate(df.ner_tags.to_list()):\n",
        "    gold = []\n",
        "    ch_start = 0\n",
        "    for l, label in enumerate(tags):\n",
        "      if label == \"O\":\n",
        "        token = df._get_value(i, 'tokens')\n",
        "        tmp_token = token[l]\n",
        "        tmp_label = label\n",
        "        tmp_start = l\n",
        "        tmp_end = l+1\n",
        "\n",
        "        gold_data_dic = {}\n",
        "        ch_end = ch_start + len(tmp_token)\n",
        "        gold_data_dic[\"file_id\"] = i\n",
        "        gold_data_dic['gold_label'] = tmp_label\n",
        "        gold_data_dic['token_start'] = tmp_start\n",
        "        gold_data_dic['token_end'] = tmp_end\n",
        "        gold_data_dic['entity_text'] = tmp_token\n",
        "        gold_data_dic['ch_start'] = ch_start\n",
        "        gold_data_dic['ch_end'] = ch_end\n",
        "        ch_start = ch_end+1\n",
        "        #print(tmp_start, tmp_end, tmp_label, tmp_token)\n",
        "        # uncomment the line below if you want to generate a file with all the tokens (entity or not)\n",
        "        #gold_data_entities.append(gold_data_dic)\n",
        "        gold_data_tokens.append(gold_data_dic)\n",
        "\n",
        "      if label != \"O\":\n",
        "        if \"B-\" in label:\n",
        "          token = df._get_value(i, 'tokens')\n",
        "          tmp_token = token[l]\n",
        "          tmp_label = label[2:]\n",
        "          tmp_start = l\n",
        "\n",
        "          out = 0\n",
        "          if l+1 < len(tags):\n",
        "            tmp_end = l+1\n",
        "            #print(l, l+1, tmp_label, tmp_token)\n",
        "            for nl in range(l+1,len(tags)):\n",
        "              #print(nl, token[nl])\n",
        "              if \"B-\" in tags[nl]:\n",
        "                out = 1\n",
        "                break\n",
        "              elif \"O\" == tags[nl]:\n",
        "                out = 1\n",
        "                break\n",
        "              elif \"I-\" in tags[nl]:\n",
        "                token = df._get_value(i, 'tokens')\n",
        "                tmp_token += \" \" + token[nl]\n",
        "                tmp_start = l\n",
        "                tmp_end = nl+1\n",
        "                #print(tmp_start, tmp_end, tmp_label, tmp_token)\n",
        "            if out == 1:\n",
        "              gold_data_dic = {}\n",
        "\n",
        "              ch_end = ch_start + len(tmp_token)\n",
        "              gold_data_dic[\"file_id\"] = i\n",
        "              gold_data_dic['gold_label'] = tmp_label\n",
        "              gold_data_dic['token_start'] = tmp_start\n",
        "              gold_data_dic['token_end'] = tmp_end\n",
        "              gold_data_dic['entity_text'] = tmp_token\n",
        "              gold_data_dic['ch_start'] = ch_start\n",
        "              gold_data_dic['ch_end'] = ch_end\n",
        "              ch_start = ch_end+1\n",
        "              #print(tmp_start, tmp_end, tmp_label, tmp_token)\n",
        "              gold_data_entities.append(gold_data_dic)\n",
        "              gold_data_tokens.append(gold_data_dic)\n",
        "\n",
        "\n",
        "  gold_data_entity = pd.DataFrame.from_records(gold_data_entities)\n",
        "  gold_data_token = pd.DataFrame.from_records(gold_data_tokens)\n",
        "  print(len(gold_data_entity), len(gold_data_token))\n",
        "  print(gold_data_entity)\n",
        "  print(gold_data_token)\n",
        "\n",
        "  # this line to save the excel file of entities only\n",
        "  gold_data_entity.to_excel(path+'gold_data_entity_CHoffsetEntitiesOnly_'+name+'.xlsx', index=False)\n",
        "\n",
        "  # this line to save the excel file with all tokens\n",
        "  gold_data_token.to_excel(path+'gold_data_entity_CHoffset_all_token_'+name+'.xlsx', index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/Train-validation-test/August2023/\"\n",
        "\n",
        "train_validation = pd.read_json(path+\"train_validation_429.json\", lines=True)\n",
        "print(\"pre-processing train_validation set\")\n",
        "preprocess(train_validation, 'train_validation_429', path)\n",
        "\n",
        "train = pd.read_json(path+\"train_353.json\", lines=True)\n",
        "print(\"pre-processing training set\")\n",
        "preprocess(train, 'train_353', path)\n",
        "\n",
        "validation = pd.read_json(path+\"validation_76.json\", lines=True)\n",
        "print(\"pre-processing validation set\")\n",
        "preprocess(validation, 'validation_76', path)\n",
        "\n",
        "test = pd.read_json(path+\"test_76.json\", lines=True)\n",
        "print(\"pre-processing testing set\")\n",
        "preprocess(test, 'test_76', path)\n",
        "\n"
      ],
      "metadata": {
        "id": "R0IkCvJKnF6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the results of en_core_med7_trf and en_core_med7_lg on testing set WITHOUT fine-tuining\n",
        "\n",
        "# 1- create one discharge summary with its NER labels\n",
        "# 2- send the summary to Med7 for prediction NER labels\n",
        "# 3- evaluate the results with Gold standard\n",
        "\n",
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "\n",
        "def testing(df, name, path):\n",
        "\n",
        "  med7 = spacy.load(name)\n",
        "\n",
        "  str_dic_lg = []\n",
        "  predict_labels_lg_dic = []\n",
        "  predict_labels_lg = []\n",
        "  for i, token in enumerate(df.tokens.to_list()):\n",
        "    token_str_lg = ' '.join(str(t) for t in token)\n",
        "    labels_lg = df._get_value(i, 'ner_tags')\n",
        "    str_dic_lg.append([token_str_lg, labels_lg])\n",
        "    predicts_lg = []\n",
        "    entities = med7(token_str_lg)\n",
        "    for e in entities.ents:\n",
        "      predict_dic = {}\n",
        "      predict_dic[\"predict_file_id\"] = i\n",
        "      predict_dic['predict_label'] = e.label_\n",
        "      predict_dic['predict_start'] = e.start\n",
        "      predict_dic['predict_end'] = e.end\n",
        "      predict_dic['predict_text'] = e.text\n",
        "      predict_dic['start_char'] = e.start_char\n",
        "      predict_dic['end_char'] = e.end_char\n",
        "\n",
        "      #print(\"e.text\", e.text)\n",
        "      #print(\"e.label_\", e.label_)\n",
        "      #print('start', e.start)\n",
        "      #print('end', e.end)\n",
        "      #print('char_span', e.char_span(e.start_char, e.end_char))\n",
        "      #print('start_char', e.start_char)\n",
        "      #print('end_char', e.end_char)\n",
        "      #print('ent_id', e.ent_id)\n",
        "      #print('ent_id_', e.ent_id_)\n",
        "      #print('ents', e.ents[0])\n",
        "      #print('label', e.label)\n",
        "      #print('id', e.id)\n",
        "      #print('id_', e.id_)\n",
        "\n",
        "      predict_labels_lg_dic.append(predict_dic)\n",
        "      predicts_lg.append([e.start, e.end, e.text, e.label_])\n",
        "    print(predict_dic)\n",
        "    predict_labels_lg.append(predicts_lg)\n",
        "\n",
        "  print(len(predict_labels_lg))\n",
        "  print(len(predict_labels_lg_dic))\n",
        "  predict_label_entity = pd.DataFrame.from_records(predict_labels_lg_dic)\n",
        "  print(predict_label_entity)\n",
        "\n",
        "  # uncomment the line below to save the output of MED7 prediction\n",
        "  predict_label_entity.to_excel(path + 'predict_label_entity_76testDataset_'+name+'.xlsx', index=False)\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/Train-validation-test/August2023/\"\n",
        "df = pd.read_json(path+\"test_76.json\", lines=True)\n",
        "model = [\"en_core_med7_lg\", \"en_core_med7_trf\"]\n",
        "for name in model:\n",
        "  print(\"testing the performance of \"+name+\" over the testing set\")\n",
        "  testing(df, name, path)\n"
      ],
      "metadata": {
        "id": "8BHr41C1NaJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this code is to save the results of prediction in suitable format to calculate the confusion matrix of TP, FN, FP, TN\n",
        "# using type match (at least part of the token text is annotated with the correct entity type)\n",
        "# and using strict match (the token text and the entity type has to be matched the gold data)\n",
        "# COR: correct annotation of type\n",
        "# INC: incorrect annotation of type\n",
        "# MIS: missing annotation by Med7\n",
        "# SPU: Spurius is for a token predicted by Med7 with an entity label but it's not in the gold data\n",
        "\n",
        "# see this website explains NER evaluation:\n",
        "# https://www.davidsbatista.net/blog/2018/05/09/Named_Entity_Evaluation/\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def processing(true_label_entity, predict_label_entity, name, path):\n",
        "\n",
        "  Eval = []\n",
        "\n",
        "  predict_label_entity_len = len(predict_label_entity)\n",
        "  type_list = []\n",
        "  strict_list = []\n",
        "  for i, row in true_label_entity.iterrows():\n",
        "    if i%500 == 0:\n",
        "\n",
        "      print(\"batch: \", i)\n",
        "    tmp = 0\n",
        "    for c, srow in predict_label_entity.iterrows():\n",
        "      #print(c)\n",
        "      if srow[0] > row[0]:\n",
        "        #print('LARGER', row[0], srow[0])\n",
        "        break\n",
        "      #if c%5000 == 0:\n",
        "        #print(\"batch c\", c)\n",
        "      Eval_dic = {}\n",
        "      if row[0] == srow[0]:\n",
        "        #print('EQUALS', row[0], srow[0])\n",
        "        if row[5] == srow[5] and row[6] == srow[6] and str(row[4]) == str(srow[4]):\n",
        "        #if str(row[4]).lower() == str(srow[4]).lower():\n",
        "          if str(row[1]).lower() == str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'COR'\n",
        "            Eval_dic['type_label'] = 'COR'\n",
        "            #print('str(row[4]).lower() == str(srow[4]).lower()', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            strict_list.append('COR')\n",
        "            type_list.append('COR')\n",
        "            #print(\"strict_list.append(COR), type_list.append(COR)\")\n",
        "            #true_label_entity = true_label_entity.drop([i])\n",
        "            #predict_label_entity = predict_label_entity.drop([c])\n",
        "            #predict_label_entity_len -= 1\n",
        "            #tmp = 1\n",
        "            #break\n",
        "          elif str(row[1]).lower() != str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'INC'\n",
        "            #print('str(row[4]).lower() == str(srow[4]).lower()', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            strict_list.append('INC')\n",
        "            type_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(INC)\")\n",
        "          true_label_entity = true_label_entity.drop([i])\n",
        "          predict_label_entity = predict_label_entity.drop([c])\n",
        "          predict_label_entity_len -= 1\n",
        "          tmp = 1\n",
        "          break\n",
        "\n",
        "        elif row[5] == srow[5] and str(row[4]) in str(srow[4]):\n",
        "          if str(row[1]).lower() == str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'COR'\n",
        "            #print('row[2] <= srow[2]', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            type_list.append('COR')\n",
        "            strict_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(COR)\")\n",
        "\n",
        "          elif str(row[1]).lower() != str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'INC'\n",
        "            #print('row[2] <= srow[2]', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            type_list.append('INC')\n",
        "            strict_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(INC)\")\n",
        "          #predict_label_entity = predict_label_entity.drop([c])\n",
        "          #predict_label_entity_len -= 1\n",
        "          #if row[3] < srow[3]:\n",
        "          true_label_entity = true_label_entity.drop([i])\n",
        "          tmp = 1\n",
        "\n",
        "\n",
        "        elif row[6] == srow[6] and str(row[4]) in str(srow[4]):\n",
        "          if str(row[1]).lower() == str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'COR'\n",
        "            #print('row[3] <= srow[3]', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            type_list.append('COR')\n",
        "            strict_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(COR)\")\n",
        "              #true_label_entity = true_label_entity.drop([i])\n",
        "\n",
        "              #break\n",
        "          elif str(row[1]).lower() != str(srow[1]).lower():\n",
        "              #print(\"equals\", i, c)\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'INC'\n",
        "            #print('row[3] <= srow[3]', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            type_list.append('INC')\n",
        "            strict_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(INC)\")\n",
        "              #true_label_entity = true_label_entity.drop([i])\n",
        "          predict_label_entity = predict_label_entity.drop([c])\n",
        "          predict_label_entity_len -= 1\n",
        "          true_label_entity = true_label_entity.drop([i])\n",
        "              #break\n",
        "          tmp = 1\n",
        "\n",
        "\n",
        "\n",
        "    if tmp == 0:\n",
        "      if i in true_label_entity.index:\n",
        "        Eval_dic = {}\n",
        "\n",
        "        Eval_dic['file_id'] = str(row[0])\n",
        "        Eval_dic['true_label'] = str(row[1]).lower()\n",
        "        Eval_dic['true_start'] = row[5]\n",
        "        Eval_dic['true_end'] = row[6]\n",
        "        Eval_dic['true_text'] = str(row[4])\n",
        "        Eval_dic['predict_file_id'] = str(srow[0])\n",
        "        Eval_dic['predict_label'] = \"O\"\n",
        "        Eval_dic['predict_start'] = row[5]\n",
        "        Eval_dic['predict_end'] = row[6]\n",
        "        Eval_dic['predict_text'] = str(row[4])\n",
        "        Eval_dic['strict_label'] = 'MIS'\n",
        "        Eval_dic['type_label'] = 'MIS'\n",
        "        Eval.append(Eval_dic)\n",
        "\n",
        "        #print(row)\n",
        "        strict_list.append('MIS')\n",
        "        type_list.append('MIS')\n",
        "        #print(\"strict_list.append(MIS), type_list.append(MIS)\")\n",
        "        true_label_entity = true_label_entity.drop([i])\n",
        "\n",
        "    #print(len(predict_label_entity), predict_label_entity_len)\n",
        "  for c, srow in predict_label_entity.iterrows():\n",
        "    #if len(predict_label_entity) > predict_label_entity_len:\n",
        "    Eval_dic = {}\n",
        "    Eval_dic['file_id'] = str(srow[0])\n",
        "    Eval_dic['true_label'] = 'O'\n",
        "    Eval_dic['true_start'] = srow[5]\n",
        "    Eval_dic['true_end'] = srow[6]\n",
        "    Eval_dic['true_text'] = str(srow[4])\n",
        "    Eval_dic['predict_file_id'] = str(srow[0])\n",
        "    Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "    Eval_dic['predict_start'] = srow[5]\n",
        "    Eval_dic['predict_end'] = srow[6]\n",
        "    Eval_dic['predict_text'] = str(srow[4])\n",
        "    Eval_dic['strict_label'] = 'SPU'\n",
        "    Eval_dic['type_label'] = 'SPU'\n",
        "    Eval.append(Eval_dic)\n",
        "    #print(srow)\n",
        "    strict_list.append('SPU')\n",
        "    type_list.append('SPU')\n",
        "    #print(\"strict_list.append(SPU), type_list.append(SPU)\")\n",
        "    predict_label_entity = predict_label_entity.drop([c])\n",
        "    predict_label_entity_len -= 1\n",
        "\n",
        "  true_predict_eval = pd.DataFrame.from_records(Eval)\n",
        "  print(len(true_predict_eval))\n",
        "  # uncomment this line to save the file, DO NOT FORGET TO CHANGE PATH AND FILE NAME\n",
        "  true_predict_eval.to_excel(path+'true_predict_label_entity_76testDataset_'+name+'.xlsx', index=False)  #true_predict_label_entity_76testDataset_en_core_med7_trf or true_predict_label_entity_76testDataset_en_core_med7_lg\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/Train-validation-test/August2023/\"\n",
        "\n",
        "true_label_entity = pd.read_excel(path+'gold_data_entity_CHoffsetEntitiesOnly_test_76.xlsx')\n",
        "print(true_label_entity)\n",
        "\n",
        "model = [\"en_core_med7_lg\", \"en_core_med7_trf\"]\n",
        "for name in model:\n",
        "  print(\"processing the output of \"+name+\" predictions over the testing set\")\n",
        "  predict_label_entity = pd.read_excel(path + 'predict_label_entity_76testDataset_'+name+'.xlsx') #predict_label_entity_76testDataset_en_core_med7_trf or predict_label_entity_76testDataset_en_core_med7_lg\n",
        "  print(predict_label_entity)\n",
        "  processing(true_label_entity, predict_label_entity, name, path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i2e_1GM7TCbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# This code is to calculate P, R, F1 scores based on matching the entity type between reference and candidate.\n",
        "# support in the output is the number of reference per entity type.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "def class_report(y_true, y_pred, path, name):\n",
        "\n",
        "  file = open(path+\"prediction_results_without_fine-tuning_\"+name+\".txt\", 'w')\n",
        "  labels = ['reason', 'ade', 'form', 'strength', 'dosage', 'drug', 'route', 'frequency', 'duration']\n",
        "  print(type(labels), labels)\n",
        "  report = classification_report(y_true, y_pred, labels = labels)\n",
        "  print(report)\n",
        "  file.writelines(report)\n",
        "\n",
        "  labels.remove('reason') # remove 'reason' label from evaluation\n",
        "  labels.remove('ade') # remove 'reason' label from evaluation\n",
        "  print(type(labels), labels)\n",
        "  report = classification_report(y_true, y_pred, labels = labels)\n",
        "  print(report)\n",
        "  file.writelines(report)\n",
        "  file.close()\n",
        "\n",
        "\n",
        "  #return report\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/Train-validation-test/August2023/\"\n",
        "model = [\"en_core_med7_lg\", \"en_core_med7_trf\"]\n",
        "for name in model:\n",
        "  print(\"caluculating P, R, F1 scores of \"+name+\" predictions over the testing set\")\n",
        "  eval_report_all = pd.read_excel(path+'true_predict_label_entity_76testDataset_'+name+'.xlsx') #predict_label_entity_76testDataset_en_core_med7_trf or predict_label_entity_76testDataset_en_core_med7_lg\n",
        "  print(\"76 Test dataset \"+name)\n",
        "  eval_report_copy_all = eval_report_all.copy()\n",
        "  y_true = eval_report_copy_all['true_label'].tolist()\n",
        "  y_pred = eval_report_copy_all['predict_label'].tolist()\n",
        "  print('type matching')\n",
        "  #all = class_report(y_true, y_pred)\n",
        "  class_report(y_true, y_pred, path, name)\n",
        "\n"
      ],
      "metadata": {
        "id": "FuBGQ2v14Z9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this code is to fine-tune Med7 with two versions\n",
        "#en_core_med7_trf en_core_med7_lg\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy import util\n",
        "from spacy.tokens import Doc\n",
        "from spacy.training import Example\n",
        "from spacy.tokens import DocBin\n",
        "from spacy.language import Language\n",
        "\n",
        "\n",
        "def customizing_pipeline_component(path, nlp: Language, offset, name):\n",
        "    file = open(path+\"loss_log.txt\", \"w\")\n",
        "\n",
        "    #optimizer = nlp.create_optimizer()\n",
        "    optimizer = nlp.resume_training()\n",
        "    print(type(offset), len(offset))\n",
        "    print(\"   Training ...\")\n",
        "    # setup the number of iterations here\n",
        "    iter = 30\n",
        "    file.writelines(\"post-training \" + name + \"for \" + str(iter) + \"iterations\\n\")\n",
        "    for _ in range(iter):\n",
        "        print(\"iteration: \" + str(_))\n",
        "        random.shuffle(offset)\n",
        "        losses = {}\n",
        "        for raw_text, entity_offsets in offset: # add character indexes\n",
        "            entities = spacy.training.offsets_to_biluo_tags(nlp.make_doc(raw_text), entity_offsets)\n",
        "            #print(entities)\n",
        "            doc = nlp.make_doc(raw_text)\n",
        "            example = Example.from_dict(doc, {\"entities\": entity_offsets})\n",
        "            #print('[example]', len([example]))\n",
        "            nlp.update([example], sgd=optimizer, losses=losses)\n",
        "        print(_, losses)\n",
        "        file.writelines(\"iteration: \"+ str(_) + str(losses)+\"\\n\")\n",
        "    file.close()\n",
        "    # save the post-trained model\n",
        "    nlp.to_disk(path + name +\"_plus\")\n",
        "\n",
        "    # Result after training\n",
        "    print(f\"Result AFTER training:\")\n",
        "    df = pd.read_json(path + \"test_76.json\", lines=True)\n",
        "\n",
        "    predict_labels_lg_dic = []\n",
        "\n",
        "    for i, token in enumerate(df.tokens.to_list()):\n",
        "      token_str_lg = ' '.join(str(t) for t in token)\n",
        "\n",
        "      entities = nlp(token_str_lg)\n",
        "      for e in entities.ents:\n",
        "        predict_dic = {}\n",
        "        predict_dic[\"predict_file_id\"] = i\n",
        "        predict_dic['predict_label'] = e.label_\n",
        "        predict_dic['predict_start'] = e.start\n",
        "        predict_dic['predict_end'] = e.end\n",
        "        predict_dic['predict_text'] = e.text\n",
        "        predict_dic['start_char'] = e.start_char\n",
        "        predict_dic['end_char'] = e.end_char\n",
        "\n",
        "        predict_labels_lg_dic.append(predict_dic)\n",
        "      print('file_id:', i)\n",
        "\n",
        "    print(len(predict_labels_lg_dic))\n",
        "    predict_label_entity = pd.DataFrame.from_records(predict_labels_lg_dic)\n",
        "    print(predict_label_entity)\n",
        "\n",
        "    # uncomment to save the output of the prediction after fine-tuning MED7\n",
        "    predict_label_entity.to_excel(path + 'test_76_'+name+'_fine_tuned_'+str(iter)+'iterations.xlsx', index=False)\n",
        "\n",
        "def main():\n",
        "    input_dir = \"/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/Train-validation-test/August2023/\"\n",
        "    print(\"read data\")\n",
        "    json = pd.read_json(input_dir + \"train_validation_429.json\", lines=True)\n",
        "    excel = pd.read_excel(input_dir + 'gold_data_entity_CHoffsetEntitiesOnly_train_validation_429.xlsx')\n",
        "    input_annotations_all = []\n",
        "    print(\"processing data\")\n",
        "    for i, token in enumerate(json.tokens.to_list()):\n",
        "      input_annotations = []\n",
        "      # create one discharge summary with its NER labels\n",
        "      token_str_lg = ' '.join(str(t) for t in token)\n",
        "      file_id =  excel[excel['file_id'] == i]\n",
        "      for i, row in file_id.iterrows():\n",
        "        input_annotations.append((int(row[5]), int(row[6]), row[1])) #(start, end, label)\n",
        "      input_annotations_all.append([token_str_lg, input_annotations])\n",
        "    print(\"post-training en_core_med7_lg\")\n",
        "    med7 = spacy.load(\"en_core_med7_lg\")\n",
        "    customizing_pipeline_component(input_dir, med7, input_annotations_all, \"en_core_med7_lg\")\n",
        "\n",
        "    # uncomment th elines below to fine-tune \"en_core_med7_trf\"\n",
        "    print(\"post-training en_core_med7_trf\")\n",
        "    med7 = spacy.load(\"en_core_med7_trf\")\n",
        "    customizing_pipeline_component(input_dir, med7, input_annotations_all, \"en_core_med7_trf\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "nYssmDPcdPcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# same code as above\n",
        "# this code is to save the results of prediction in suitable format to calculate the confusion matrix of TP, FN, FP, TN\n",
        "# using type match (at least part of the token text is annotated with the correct entity type)\n",
        "# and using strict match (the token text and the entity type has to be matched the gold data)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def processing(true_label_entity, predict_label_entity, name, path):\n",
        "\n",
        "  Eval = []\n",
        "\n",
        "  predict_label_entity_len = len(predict_label_entity)\n",
        "  type_list = []\n",
        "  strict_list = []\n",
        "  for i, row in true_label_entity.iterrows():\n",
        "    if i%500 == 0:\n",
        "\n",
        "      print(\"batch: \", i)\n",
        "    tmp = 0\n",
        "    for c, srow in predict_label_entity.iterrows():\n",
        "      #print(c)\n",
        "      if srow[0] > row[0]:\n",
        "        #print('LARGER', row[0], srow[0])\n",
        "        break\n",
        "      #if c%5000 == 0:\n",
        "        #print(\"batch c\", c)\n",
        "      Eval_dic = {}\n",
        "      if row[0] == srow[0]:\n",
        "        #print('EQUALS', row[0], srow[0])\n",
        "        if row[5] == srow[5] and row[6] == srow[6] and str(row[4]) == str(srow[4]):\n",
        "        #if str(row[4]).lower() == str(srow[4]).lower():\n",
        "          if str(row[1]).lower() == str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'COR'\n",
        "            Eval_dic['type_label'] = 'COR'\n",
        "            #print('str(row[4]).lower() == str(srow[4]).lower()', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            strict_list.append('COR')\n",
        "            type_list.append('COR')\n",
        "            #print(\"strict_list.append(COR), type_list.append(COR)\")\n",
        "            #true_label_entity = true_label_entity.drop([i])\n",
        "            #predict_label_entity = predict_label_entity.drop([c])\n",
        "            #predict_label_entity_len -= 1\n",
        "            #tmp = 1\n",
        "            #break\n",
        "          elif str(row[1]).lower() != str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'INC'\n",
        "            #print('str(row[4]).lower() == str(srow[4]).lower()', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            strict_list.append('INC')\n",
        "            type_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(INC)\")\n",
        "          true_label_entity = true_label_entity.drop([i])\n",
        "          predict_label_entity = predict_label_entity.drop([c])\n",
        "          predict_label_entity_len -= 1\n",
        "          tmp = 1\n",
        "          break\n",
        "\n",
        "        elif row[5] == srow[5] and str(row[4]) in str(srow[4]):\n",
        "          if str(row[1]).lower() == str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'COR'\n",
        "            #print('row[2] <= srow[2]', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            type_list.append('COR')\n",
        "            strict_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(COR)\")\n",
        "\n",
        "          elif str(row[1]).lower() != str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'INC'\n",
        "            #print('row[2] <= srow[2]', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            type_list.append('INC')\n",
        "            strict_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(INC)\")\n",
        "          #predict_label_entity = predict_label_entity.drop([c])\n",
        "          #predict_label_entity_len -= 1\n",
        "          #if row[3] < srow[3]:\n",
        "          true_label_entity = true_label_entity.drop([i])\n",
        "          tmp = 1\n",
        "\n",
        "\n",
        "        elif row[6] == srow[6] and str(row[4]) in str(srow[4]):\n",
        "          if str(row[1]).lower() == str(srow[1]).lower():\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'COR'\n",
        "            #print('row[3] <= srow[3]', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            type_list.append('COR')\n",
        "            strict_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(COR)\")\n",
        "              #true_label_entity = true_label_entity.drop([i])\n",
        "\n",
        "              #break\n",
        "          elif str(row[1]).lower() != str(srow[1]).lower():\n",
        "              #print(\"equals\", i, c)\n",
        "            Eval_dic['file_id'] = str(row[0])\n",
        "            Eval_dic['true_label'] = str(row[1]).lower()\n",
        "            Eval_dic['true_start'] = row[5]\n",
        "            Eval_dic['true_end'] = row[6]\n",
        "            Eval_dic['true_text'] = str(row[4])\n",
        "            Eval_dic['predict_file_id'] = str(srow[0])\n",
        "            Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "            Eval_dic['predict_start'] = srow[5]\n",
        "            Eval_dic['predict_end'] = srow[6]\n",
        "            Eval_dic['predict_text'] = str(srow[4])\n",
        "            Eval_dic['strict_label'] = 'INC'\n",
        "            Eval_dic['type_label'] = 'INC'\n",
        "            #print('row[3] <= srow[3]', Eval_dic)\n",
        "            Eval.append(Eval_dic)\n",
        "\n",
        "            type_list.append('INC')\n",
        "            strict_list.append('INC')\n",
        "            #print(\"strict_list.append(INC), type_list.append(INC)\")\n",
        "              #true_label_entity = true_label_entity.drop([i])\n",
        "          predict_label_entity = predict_label_entity.drop([c])\n",
        "          predict_label_entity_len -= 1\n",
        "          true_label_entity = true_label_entity.drop([i])\n",
        "              #break\n",
        "          tmp = 1\n",
        "\n",
        "\n",
        "\n",
        "    if tmp == 0:\n",
        "      if i in true_label_entity.index:\n",
        "        Eval_dic = {}\n",
        "\n",
        "        Eval_dic['file_id'] = str(row[0])\n",
        "        Eval_dic['true_label'] = str(row[1]).lower()\n",
        "        Eval_dic['true_start'] = row[5]\n",
        "        Eval_dic['true_end'] = row[6]\n",
        "        Eval_dic['true_text'] = str(row[4])\n",
        "        Eval_dic['predict_file_id'] = str(srow[0])\n",
        "        Eval_dic['predict_label'] = \"O\"\n",
        "        Eval_dic['predict_start'] = row[5]\n",
        "        Eval_dic['predict_end'] = row[6]\n",
        "        Eval_dic['predict_text'] = str(row[4])\n",
        "        Eval_dic['strict_label'] = 'MIS'\n",
        "        Eval_dic['type_label'] = 'MIS'\n",
        "        Eval.append(Eval_dic)\n",
        "\n",
        "        #print(row)\n",
        "        strict_list.append('MIS')\n",
        "        type_list.append('MIS')\n",
        "        #print(\"strict_list.append(MIS), type_list.append(MIS)\")\n",
        "        true_label_entity = true_label_entity.drop([i])\n",
        "\n",
        "    #print(len(predict_label_entity), predict_label_entity_len)\n",
        "  for c, srow in predict_label_entity.iterrows():\n",
        "    #if len(predict_label_entity) > predict_label_entity_len:\n",
        "    Eval_dic = {}\n",
        "    Eval_dic['file_id'] = str(srow[0])\n",
        "    Eval_dic['true_label'] = 'O'\n",
        "    Eval_dic['true_start'] = srow[5]\n",
        "    Eval_dic['true_end'] = srow[6]\n",
        "    Eval_dic['true_text'] = str(srow[4])\n",
        "    Eval_dic['predict_file_id'] = str(srow[0])\n",
        "    Eval_dic['predict_label'] = str(srow[1]).lower()\n",
        "    Eval_dic['predict_start'] = srow[5]\n",
        "    Eval_dic['predict_end'] = srow[6]\n",
        "    Eval_dic['predict_text'] = str(srow[4])\n",
        "    Eval_dic['strict_label'] = 'SPU'\n",
        "    Eval_dic['type_label'] = 'SPU'\n",
        "    Eval.append(Eval_dic)\n",
        "    #print(srow)\n",
        "    strict_list.append('SPU')\n",
        "    type_list.append('SPU')\n",
        "    #print(\"strict_list.append(SPU), type_list.append(SPU)\")\n",
        "    predict_label_entity = predict_label_entity.drop([c])\n",
        "    predict_label_entity_len -= 1\n",
        "\n",
        "  true_predict_eval = pd.DataFrame.from_records(Eval)\n",
        "  print(len(true_predict_eval))\n",
        "  # if you changed the number of iterations to other than 30 change it in the line below\n",
        "  true_predict_eval.to_excel(path+'true_predict_label_entity_76testDataset_'+name+'_fine_tuned_30iterations.xlsx', index=False)  #true_predict_label_entity_76testDataset_en_core_med7_trf or true_predict_label_entity_76testDataset_en_core_med7_lg\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/Train-validation-test/August2023/\"\n",
        "\n",
        "true_label_entity = pd.read_excel(path+'gold_data_entity_CHoffsetEntitiesOnly_test_76.xlsx')\n",
        "print(true_label_entity)\n",
        "\n",
        "model = [\"en_core_med7_lg\", \"en_core_med7_trf\"]\n",
        "for name in model:\n",
        "  print(\"processing the output of \"+name+\" predictions over the testing set\")\n",
        "\n",
        "  # make sure the number of iterations is correct in the file name\n",
        "  # if you changed the number of iterations to other than 30 change it in the line below\n",
        "  predict_label_entity = pd.read_excel(path + 'test_76_'+name+'_fine_tuned_30iterations.xlsx') #predict_label_entity_76testDataset_en_core_med7_trf or predict_label_entity_76testDataset_en_core_med7_lg\n",
        "  print(predict_label_entity)\n",
        "  processing(true_label_entity, predict_label_entity, name, path)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fuzJRKAPvgfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# same code as above\n",
        "# This code is to calculate P, R, F1 scores based on matching the entity type between reference and candidate.\n",
        "# support in the output is the number of reference per entity type.\n",
        "\n",
        "# DONOT FORGET TO CHANGE PATHS AND FILES NAMES\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "def class_report(y_true, y_pred, path, name):\n",
        "\n",
        "  file = open(path+\"prediction_results_after_fine-tuning_\"+name+\".txt\", 'w')\n",
        "  labels = ['reason', 'ade', 'form', 'strength', 'dosage', 'drug', 'route', 'frequency', 'duration']\n",
        "  print(type(labels), labels)\n",
        "  report = classification_report(y_true, y_pred, labels = labels)\n",
        "  print(report)\n",
        "  file.writelines(report)\n",
        "\n",
        "  labels.remove('reason') # remove 'reason' label from evaluation\n",
        "  labels.remove('ade') # remove 'reason' label from evaluation\n",
        "  print(type(labels), labels)\n",
        "  report = classification_report(y_true, y_pred, labels = labels)\n",
        "  print(report)\n",
        "  file.writelines(report)\n",
        "  file.close()\n",
        "\n",
        "\n",
        "  #return report\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/Train-validation-test/August2023/\"\n",
        "model = [\"en_core_med7_lg\", \"en_core_med7_trf\"]\n",
        "for name in model:\n",
        "  print(\"caluculating P, R, F1 scores of \"+name+\" predictions over the testing set AFTER fine-tuning on 429 n2c2-2018 training set with 30 iterations\")\n",
        "  eval_report_all = pd.read_excel(path+'true_predict_label_entity_76testDataset_'+name+'_fine_tuned_30iterations.xlsx') #predict_label_entity_76testDataset_en_core_med7_trf or predict_label_entity_76testDataset_en_core_med7_lg\n",
        "  print(\"76 Test dataset \"+name)\n",
        "  eval_report_copy_all = eval_report_all.copy()\n",
        "  y_true = eval_report_copy_all['true_label'].tolist()\n",
        "  y_pred = eval_report_copy_all['predict_label'].tolist()\n",
        "  print('type matching')\n",
        "  #all = class_report(y_true, y_pred)\n",
        "  class_report(y_true, y_pred, path, name)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZzgYJNAkwIao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All code below is for pre-process Brat annotaion (NER)\n",
        "# skip if you don't need"
      ],
      "metadata": {
        "id": "HndqlNj91zEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkmE9ECUMYt7"
      },
      "outputs": [],
      "source": [
        "!python /content/drive/MyDrive/Reasearch_Assistantship/HILO_project/brat2CoNLL-main/brat2CoNLL/format_convertor2.py --input_dir=/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/train --output_file=/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/train/output/output.txt\n",
        "!python /content/drive/MyDrive/Reasearch_Assistantship/HILO_project/brat2CoNLL-main/brat2CoNLL/format_convertor2.py --input_dir=/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/valid --output_file=/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/valid/output/output.txt\n",
        "!python /content/drive/MyDrive/Reasearch_Assistantship/HILO_project/brat2CoNLL-main/brat2CoNLL/format_convertor2.py --input_dir=/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/test --output_file=/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/test/output/output.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Edit pre-process\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/train/output/output.xlsx')\n",
        "print(df.columns)\n",
        "\n",
        "df_copy = df.copy()\n",
        "line = df_copy.index[df_copy['Unnamed: 2'] == \"O\"].tolist()\n",
        "print(len(df_copy))\n",
        "print(len(line))\n",
        "df2 = pd.DataFrame(columns = ['Token', 'Label', 'Unnamed: 2'])\n",
        "for id in line:\n",
        "  tmp = df_copy.iloc[id]\n",
        "  #print(tmp[2])\n",
        "\n",
        "  test = pd.DataFrame({'Token' : tmp[0], 'Label' : tmp[2], 'Unnamed: 2' : pd.NA}, index=[id])\n",
        "  df2 = pd.concat([df2, test], axis=0, ignore_index=False)\n",
        "  #df2 = df2.append(test, ignore_index=False)\n",
        "  test = pd.DataFrame({'Token' : tmp[1], 'Label' : tmp[2], 'Unnamed: 2' : pd.NA}, index=[id+1])\n",
        "  df2 = pd.concat([df2, test], axis=0, ignore_index=False)\n",
        "  #df2 = df2.append(test, ignore_index=False)\n",
        "\n",
        "  #print(tmp)\n",
        "print(len(df2))\n",
        "print(df_copy.loc[[29490]])\n",
        "df_copy = df_copy.drop(line)\n",
        "print(len(df_copy))\n",
        "line = df2.iloc[0]\n",
        "print(line)\n",
        "line = df2.iloc[1]\n",
        "print(line)\n",
        "# https://huggingface.co/course/chapter7/2\n",
        "df3 = pd.concat([df2, df_copy], axis=0)\n",
        "print(df3)\n",
        "df3.to_excel('/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/train/output/output2.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "OAqHko1_AXPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split all discharge sammaries into seperate files, a file for a discharge summary\n",
        "\n",
        "df = pd.read_excel('/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/valid/output/output.xlsx', index=False)\n",
        "print(len(df))\n",
        "print(df.columns)\n",
        "\n",
        "df_copy = df.copy()\n",
        "line = []\n",
        "for i, row in df_copy.iterrows():\n",
        "  #print(i, row[0], row[1])\n",
        "  if \".txt\" in row[1]:\n",
        "    print(i, row[0], row[1])\n",
        "    line.append(i)\n",
        "print(len(line))\n",
        "print(line)\n",
        "i = 0\n",
        "while i+1 <= len(line):\n",
        "  if i+1 == len(line):\n",
        "    df_slice = df_copy.iloc[line[i]:len(df_copy), :]\n",
        "    txt_ind = df_slice[\"Label\"].tolist()\n",
        "    print(txt_ind[0])\n",
        "    df_slice.to_excel('/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/valid/output/'+txt_ind[0]+'.xlsx', index=False)\n",
        "  else:\n",
        "    df_slice = df_copy.iloc[line[i]:line[i+1], :]\n",
        "    txt_ind = df_slice[\"Label\"].tolist()\n",
        "    print(txt_ind[0])\n",
        "    df_slice.to_excel('/content/drive/MyDrive/Reasearch_Assistantship/HILO_project/n2c2_2018/valid/output/'+txt_ind[0]+'.xlsx', index=False)\n",
        "  i +=1"
      ],
      "metadata": {
        "id": "fCfhUrmQhL_f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}